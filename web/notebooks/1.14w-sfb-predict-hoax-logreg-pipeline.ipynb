{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "315e258b-7258-48f2-b5ee-548258bd6456",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Predict \"Hoax\" With Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa641e40-2262-43b5-a05b-e2b97513c29e",
   "metadata": {},
   "source": [
    "- There was a typo and a feature slipped through that wasn't supposed to\n",
    "    - ➜ fixed\n",
    "    - The sets are the same now, but the phenomenon is remaining.\n",
    "- Maybe it's because the intercept was scaled to zero?  \n",
    "    - ➜ Try only scaling the original floats.\n",
    "    - Score improved to .54/.5 , but unscaled remains .6\n",
    "- Look at (unscaled_coeff / $\\sigma$) to understand feature importance\n",
    "    - ➜ Try repeating the regression with these features only\n",
    "    - Score improved to .55/.5 , and unscaled remains .58\n",
    "- Checked Lasso (with all features)\n",
    "    - ➜ same results as Ridge: .54/.5\n",
    "- Relaxed my limitation of C,\n",
    "    - ➜ improved to .57/.5 with C=6\n",
    "- Ran logistic regression on unscaled features with no regularization\n",
    "    - ➜ improved to .61/.5\n",
    "    - Far out-performed the paper-author's models\n",
    "- Let's try SFS with scaled features\n",
    "    - Success!\n",
    "- Conclusion:\n",
    "    - The unscaled data was causing regularization to do feature selection in a better way.\n",
    "    - When the feature selection was improved with "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7010358a-9893-4d93-acd1-cafda96c645e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### When to use sklearn's GridSearchCV to wrap SFS?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8a9611-a187-4e16-a889-4e5a4dc71a6c",
   "metadata": {},
   "source": [
    "- Technical particularity:\n",
    "    - It's only possible to get access to the SFS instance for the param combination that GridSearchCV found to be optimal.\n",
    "    - This mitigates output complexity, but prevents thorough review.\n",
    "    - It would prevent a review of both SFFS and SFBS within the same gridsearch as is done here, for instance.\n",
    "- Pros\n",
    "    - GridSearchCV is great for automated production applications, to make the code robust, concise, and palatable for other users.\n",
    "- Cons\n",
    "    - GridSearchCV wouldn't let me do a viz overview of the param_grid outputs.\n",
    "    - (it's grid ***search***, not grid ***exploration***.) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8445bee5-3296-4ef7-815a-b402f23762f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Previous thoughts on why not to use sklearn's GridSearchCV with SFS:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a37b07b6-c047-4028-ac60-3cd6008ddff0",
   "metadata": {},
   "source": [
    "sklearn.model_selection.GridSearchCV can only optimize one hyperparameter at a time. It cannot require two hyperparameters to be fixed together.  \n",
    "However to implement SFS in a pipeline with GridSearchCV requires two instances of the estimator:\n",
    "\n",
    "- one instance est_sfs for the estimator in SFS, and \n",
    "- another instance est_scor at the end of the pipeline to allow it to be used to fit a model.\n",
    "\n",
    "But then, these two estimator instances will have two separate/parallel sets of hyperparameters. \n",
    "\n",
    "Consider that the model used for these instances is sklearn.linear_model.LogisticRegression, which has a regularization hyperparameter C.  \n",
    "The C used by the LogisticRegression inside SFS is used to select features, and the C at the end of the pipeline is used by the gridsearch to score each model run.  \n",
    "\n",
    "Three solution alternatives to make sure the two C's are the same for each model run:\n",
    "1. Use GridSearch to wrap the pipeline and param_grid, with an unused stand-in estimator at the end of the pipeline. Write a custom function to analyze and score the SFS output pulled directly from my_pipeline.steps[index] etc.\n",
    "2. Write my own custom gridsearch function.\n",
    "3. Rewrite the GridSearchCV code as was done in this SOF answer (without fully-posted code)\n",
    "\n",
    "documentation here ([link](https://stackoverflow.com/questions/48831851/how-to-pass-two-estimator-objects-to-sklearns-gridsearchcv-so-that-they-have-th))\n",
    "\n",
    "Another perspective:\n",
    "- Maybe doing the scoring with a different estimator est_scor is better:\n",
    "    - The main point of a diverse paramgrid within SFS is develop a diverse output of feature sets.\n",
    "    - That's an entirely separate goal from tuning optimal hyperparameters for the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cf4c59-546e-453f-9aef-cce814551a91",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get hoax data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36311d5e-beb7-471f-a963-ed1f57c60242",
   "metadata": {
    "tags": []
   },
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "522dd10f-5501-4d60-b29c-3a857f23ba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, patsy\n",
    "import pandas as pd, numpy as np\n",
    "from datetime import datetime as dt\n",
    "from sklearn.model_selection import train_test_split\n",
    "path = '/home/bhrdwj/git/predwikt/data/raw/wiki_reliability/unzipped/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c93dfd55-0405-4534-ad2d-db33b0b1de8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_data_raw = (pd.read_csv(path+'hoax_features.csv', usecols=lambda x: x not in ['Unnamed: 0'])\n",
    "       .rename(columns={'headings_by_level(2)':'headings_by_level_2', 'revision_id.key':'revision_id_key'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d507d75-7553-4319-9c39-d80baea4166f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33085a9-6220-4d98-bd40-940dbfec13d7",
   "metadata": {},
   "source": [
    "- Dataset has paired observations: one for positive and one for negative for particular articles.\n",
    "- Train-test-split needs to keep paired observations in the same splits, for useful training to happen "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f4b2da-0012-4cba-b7cb-d0f56e092dac",
   "metadata": {},
   "source": [
    "#### Organize paired data by making **indexing series**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745d157e-4d60-40b9-b45b-a31976ae6d96",
   "metadata": {},
   "source": [
    "- Indexing series ≡\n",
    "    - index: revision_id\n",
    "    - value: revision_id_key\n",
    "- Make indexing series for both:\n",
    "    - hoaxes: positive\n",
    "    - not hoaxes: negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9af20039-584c-4405-a1fc-94fb3697c368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    1398\n",
       "0.0    1390\n",
       "Name: has_template, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_data_raw.has_template.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08662150-a1c8-4bb1-aaec-213410a7354d",
   "metadata": {},
   "source": [
    "- Note there are eight excess observations of positive (hoax) revs:\n",
    "    - therefore, perform train-test split based on non-hoax first,\n",
    "    - then use indices of that split to split hoaxes accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35f30aaf-6d36-4c06-a857-6b6b717e8514",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = feature_data_raw[['revision_id', 'revision_id_key', 'has_template']]\n",
    "revid_ser_neg = df.copy().loc[df.has_template==0].set_index('revision_id')['revision_id_key']\n",
    "revid_ser_pos = df.copy().loc[df.has_template==1].set_index('revision_id')['revision_id_key']\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9cacc0-02a2-4289-938b-4777886cad99",
   "metadata": {},
   "source": [
    "#### Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669585ff-f339-4674-a2e6-c5c4a4a8cb9a",
   "metadata": {},
   "source": [
    "Split the negative revids (indices)  \n",
    "Get positive indices from revision_id_key (values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1cfa337d-351a-4842-9968-ba52d362d8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "revid_neg_tr, revid_neg_te = train_test_split(revid_ser_neg, test_size=.2, random_state=0)\n",
    "revid_pos_tr = revid_ser_pos.loc[revid_neg_tr.values]\n",
    "revid_pos_te = revid_ser_pos.loc[revid_neg_te.values]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cf3ac2-7e24-4b6a-87da-a6baa3e28806",
   "metadata": {},
   "source": [
    "Reconcatenate neg and pos observations into train and test revision_id indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b6eed864-538d-45d7-a0e2-9b28d0f39c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "revid_tr = pd.concat((revid_pos_tr, revid_neg_tr))\n",
    "revid_te = pd.concat((revid_pos_te, revid_neg_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3079d2-be84-44bf-81a3-a82fbe206e1b",
   "metadata": {},
   "source": [
    "Select original dataset into train and test using revision_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e863c433-eeda-44de-ac19-daffddb6e753",
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_revid = feature_data_raw.set_index('revision_id')\n",
    "dftr = fea_revid.loc[revid_tr.index].dropna()\n",
    "dfte = fea_revid.loc[revid_te.index].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bfd45d-e36e-49b6-a9cb-6484044c46a0",
   "metadata": {},
   "source": [
    "Clean namespace and view data summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1e831562-e1a0-449a-9a6d-7c29055d1e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "del revid_ser_neg, revid_ser_pos\n",
    "del revid_neg_tr, revid_neg_te, revid_pos_tr, revid_pos_te\n",
    "del revid_tr, revid_te, fea_revid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "af05ed3d-dc88-46c9-8feb-54ceedd01393",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftr[dftr.columns.difference(['page_id','revision_id_key','has_template'])].describe().T.sort_values(by='mean');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3973ad-4155-410f-96d4-2cf48761841f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6167ede2-3aca-4ad6-8ad5-967da582800e",
   "metadata": {},
   "source": [
    "##### Separate X and y, remove non-features, onehotify categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8cd82483-08e1-4b76-887e-0204310cddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ytr = dftr.has_template\n",
    "Xtr = dftr[dftr.columns.difference(['page_id','revision_id_key','has_template'])]\n",
    "Xtr = patsy.dmatrix('~ '+' + '.join(Xtr.columns), data=Xtr, NA_action='drop', return_type='dataframe')\n",
    "\n",
    "yte = dfte.has_template\n",
    "Xte = dfte[dfte.columns.difference(['page_id','revision_id_key','has_template'])]\n",
    "Xte = patsy.dmatrix('~ '+' + '.join(Xte.columns), data=Xte, NA_action='drop', return_type='dataframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b90378-19ed-4e61-859d-aa543b6a4337",
   "metadata": {},
   "source": [
    "##### Make complete list of features in case the test (or train) set doesn't include any of a rare class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b783997c-9cc3-4e9f-afd1-ea18ed0bf9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcols = list(\n",
    "    set(Xtr.columns.tolist())\n",
    "    .union(set(Xte.columns.tolist()))\n",
    ")\n",
    "\n",
    "for col in Xcols:\n",
    "    if col not in Xte:\n",
    "        Xte[col] = 0\n",
    "    if col not in Xtr:\n",
    "        Xtr[col] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea50d923-5511-4e6a-96a9-df2a30ab630e",
   "metadata": {},
   "source": [
    "##### Reindex with the complete feature list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "15a879d3-4f36-438c-bfb7-b14351ae50b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2221, 25), (556, 25))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr = Xtr.reindex(columns=Xcols)\n",
    "Xte = Xte.reindex(columns=Xcols)\n",
    "Xtr.shape, Xte.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cf35df-ca3f-4d84-8b8f-1c713b491e4c",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e240ab32-e6c4-4444-b038-4e22ebc59adf",
   "metadata": {
    "tags": []
   },
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "47998023-f505-442c-97d1-f9e3832dc3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970e8025-1fdc-4c1c-9f25-e8b9c844114e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c46fcb-9c46-415b-b2bc-1caaa0f589fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### get_fitfeats_sfs_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5ad3492f-bc9f-4139-a639-c4911599779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bh_sfs_gridsearch(Xtr, ytr, pipe, param_grid:dict):\n",
    "    \"\"\"\n",
    "    Concept:\n",
    "        Like sklearn's GridSearch, but relying on sfs for cross-validation.\n",
    "        Returns all feature sets and cv scores from SFFS and SFBS runs and sub-runs for each params combo.\n",
    "        (sklearn's GridSearch only returns model outputs from its winning param combo)\n",
    "    Args:\n",
    "        Xtr: pd.DataFrame of features\n",
    "        ytr: pd.Series target\n",
    "        pipe: sklearn Pipeline ending in a mlxtend SequentialFeatureSelector instance.\n",
    "        param_grid: dict of lists, params of pipe, input for sklearn ParameterGrid\n",
    "    Returns:\n",
    "        dict:\n",
    "        - keys are numbers starting in 1, for each cell of ParameterGrid\n",
    "        - values are lists of feature names\n",
    "    \"\"\"\n",
    "    print(f'start time: {dt.now()}')\n",
    "    pg = {i:j for i,j in enumerate(ParameterGrid(param_grid), start=1)}\n",
    "    sfs_featdict = {}\n",
    "    sfs_scoredict = {}\n",
    "    for i in pg:\n",
    "        pipe.set_params(**pg[i]).fit(Xtr, ytr)\n",
    "        k_feats = pg[i]['sfs__k_features']\n",
    "        idx_tup = pipe.steps[-1][1].get_metric_dict()[k_feats]['feature_idx']\n",
    "        \n",
    "        d = {k:list(v['feature_idx']) for k,v in pipe.steps[1][1].subsets_.items()}  # IMPROVEMENT: change pipe.steps[1] to directly look for the sfs step\n",
    "        for j in d: d[j] = Xtr.columns[d[j]]\n",
    "        sfs_featdict[i] = d\n",
    "        \n",
    "        s = {k:v['avg_score'] for k,v in pipe.steps[1][1].subsets_.items()} # IMPROVEMENT: change pipe.steps[1] to directly look for the sfs step\n",
    "        sfs_scoredict[i] = s\n",
    "    print(f'finish time: {dt.now()}')\n",
    "    return sfs_featdict, sfs_scoredict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b455e5-00a7-435f-a71b-32d868985069",
   "metadata": {
    "tags": []
   },
   "source": [
    "### instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0eab8d0-f6c1-4aa8-892c-3568fc7bc626",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "lr_sfs = LogisticRegression(penalty='l2', max_iter=1000, fit_intercept=True)\n",
    "cv_sfs = StratifiedKFold(n_splits=5, shuffle=False)\n",
    "sfs = SFS(estimator=lr_sfs, forward=True, floating=False, scoring='accuracy', cv=cv_sfs)\n",
    "sffs = SFS(estimator=lr_sfs, forward=True, floating=True, scoring='accuracy', cv=cv_sfs)\n",
    "sfbs = SFS(estimator=lr_sfs, forward=False, floating=True, scoring='accuracy', cv=cv_sfs)\n",
    "sfs_pipe = Pipeline([('scaler', scaler),('sfs', sfs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bde31d-f823-4c71-8529-8cabea8cd79e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0c7045-80ac-4492-9a44-ead915eeada2",
   "metadata": {},
   "source": [
    "#### sffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a5b38a34-eece-4fee-bb22-b62dc7d6749e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2022-01-14 16:17:47.109755\n",
      "finish time: 2022-01-14 16:20:34.958287\n"
     ]
    }
   ],
   "source": [
    "sfs_pipe_param_grid = {\n",
    "    'sfs': [sffs, sfbs],\n",
    "    'sfs__k_features': [1, len(Xtr.columns)],\n",
    "    'sfs__estimator': [lr_sfs],\n",
    "    'sfs__estimator__C': [.013]\n",
    "}\n",
    "\n",
    "sfs_featdict, sfs_scoredict = bh_sfs_gridsearch(Xtr, ytr, sfs_pipe, sfs_pipe_param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f70c6c1-53de-4a18-a059-281d6f8b0a96",
   "metadata": {},
   "source": [
    "#### pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1e428d-65af-4333-a98c-c547123f705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../data/processed/sfs_scoredict.StratifiedKFoldkle','wb+') as f:\n",
    "    pickle.dump(sfs_scoredict, f)\n",
    "with open('../data/processed/sfs_featdict.pickle','wb+') as f:\n",
    "    pickle.dump(sfs_featdict, f)\n",
    "\n",
    "# with open('../data/processed/sfs_featdict.pickle','rb') as f:\n",
    "#     sfs_featdict = pickle.load(f)\n",
    "# with open('../data/processed/sfs_scoredict.pickle','rb') as f:\n",
    "#     sfs_scoredict = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8deb71-fd2e-4445-a1d9-65c06204dd1f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Manage model output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76649321-4416-4531-8a69-7bd4d125965a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### extract feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0b6478-e6a7-423c-b754-8d10e643c801",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### get onehot df ~ features selected by sfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e5e94c-a99f-4ac7-8962-81fc1c9f862d",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### munge_onehotdf_from_sfs_featdict (function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6438af4-ad74-4700-818f-42821419e881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def munge_onehotdf_from_sfs_featdict(sfs_featdict):\n",
    "    \n",
    "    # simple 1D list of sfs  feats\n",
    "    sfs_feat_set = set()\n",
    "    for i in sfs_featdict:              # runs\n",
    "        for j in sfs_featdict[i]:       # kfeats\n",
    "            sfs_feats = list(sfs_feat_set.union(set(sfs_featdict[i][j])))\n",
    "    \n",
    "    # make multiindex columns and empty dataframe\n",
    "    col = pd.MultiIndex.from_tuples(\n",
    "        [(j,k) for j in sfs_featdict for k in sfs_featdict[j]])\n",
    "    idx = pd.Index(sfs_feats, name='feature')\n",
    "    df = pd.DataFrame('-', idx, col)\n",
    "    \n",
    "    # insert onehots into df\n",
    "    for i in sfs_feats:                           # feats\n",
    "        for j in sfs_featdict:                        # runs\n",
    "            for k in sfs_featdict[j]:             # steps within run\n",
    "                df.loc[i,(j,k)] = int(i in sfs_featdict[j][k])\n",
    "    \n",
    "    df = df.astype(int) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0481c26e-a80e-4b34-83e3-9e001f6c5bff",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### get df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0e9a69-35be-42e9-a7a5-80af854e688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_onehots = munge_onehotdf_from_sfs_featdict(sfs_featdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bab933-3331-433a-b1be-58970b393f5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### get simple 1D lists of sfs runs, kfeats, and feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a653fc4-e071-45ab-a72a-9a11399de70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_runs = list(sfs_featdict.keys())\n",
    "\n",
    "sfs_feat_set, sfs_kfeats_set = set(), set()\n",
    "for i in sfs_featdict:              # runs\n",
    "    for j in sfs_featdict[i]:       # kfeats\n",
    "        sfs_feats = list(sfs_feat_set.union(set(sfs_featdict[i][j])))\n",
    "        sfs_kfeats = list(sfs_kfeats_set.union(set([j])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecc3f6a-425c-4523-a38f-41457d5b7f39",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### sort the index of features by occurence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6264fc-ec95-45cf-9832-47c8ce364b9f",
   "metadata": {},
   "source": [
    "##### count occurrences of features to sort the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3557054-1dbd-45a6-b848-98c625bda276",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "sfs_feat_usecounts = sfs_onehots.loc[:,idx[1,:]].sum(axis=1)\n",
    "for i in sfs_featdict:\n",
    "    sfs_feat_usecounts += sfs_onehots.loc[:,idx[i,:]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee0f850-416d-45eb-a86c-7d498f330d4e",
   "metadata": {},
   "source": [
    "##### sort features by frequency of occurence in sfs cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122e3844-82c9-43bc-ac47-1af518b1cfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_onehots = sfs_onehots.reindex(index=sfs_feat_usecounts.sort_values(ascending=False).index)\n",
    "sfs_onehots = sfs_onehots.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9a46d1-6b4d-4823-bf7e-54ccde89d43e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Viz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22fb8d7-ff69-4a1f-91db-a8f8be9f7c4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c2f385-0a14-4870-92a1-c2b7358002a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2c4ff4-c49f-48d2-8750-4f74ed9d1ddd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### plot feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac95e0d-935d-413d-a020-6a09ba4816cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_fig, ax = plt.subplots(1,2, figsize=(16,8))\n",
    "feat_fig.subplots_adjust(wspace=.5)\n",
    "\n",
    "(sns.heatmap(\n",
    "    sfs_onehots.loc[:,idx[2,:]].T.droplevel(level=0).T, \n",
    "    ax=ax[0], cbar=False)\n",
    "    .set(ylabel=None, xlabel='kfeats')   \n",
    ")\n",
    "(sns.heatmap(\n",
    "    sfs_onehots.loc[:,idx[3,:]].T.droplevel(level=0).T, \n",
    "    ax=ax[1], cbar=False)\n",
    "    .set(ylabel=None, xlabel='kfeats')\n",
    ")\n",
    "\n",
    "ax[0].set_title('Sequential Floating Forward Selection')\n",
    "ax[1].set_title('Sequential Floating Backward Selection')\n",
    "feat_fig.suptitle('Logistic Regression: Features selected, graphed against k_features')\n",
    "feat_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a237947-1b3f-4f53-ba4f-c731b1a2bc61",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### plot cv scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d2c512-3dde-49ac-b514-8a30dc24bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "scor_fig, ax = plt.subplots(1,2, figsize=(14,4))\n",
    "scor_fig.subplots_adjust(wspace=.4)\n",
    "\n",
    "pd.Series(sfs_scoredict[2]).plot(ax=ax[0])\n",
    "pd.Series(sfs_scoredict[3]).plot(ax=ax[1])\n",
    "for axis in ax:\n",
    "    axis.set_xlabel('kfeats')\n",
    "    axis.set_ylabel('accuracy')\n",
    "ax[0].set_title('Sequential Floating Forward Selection')\n",
    "ax[1].set_title('Sequential Floating Backward Selection')\n",
    "scor_fig.suptitle('Logistic Regression: Cross-validation accuracy score from SFS (baseline accuracy 0.5)')\n",
    "scor_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074cc904-6b04-46c2-8754-87e99c4c4b66",
   "metadata": {},
   "source": [
    "### Get top 5 feats sets by cross-val score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283d1720-d935-4df8-8045-7a6ac4e0aba4",
   "metadata": {},
   "source": [
    "##### create empty dataframe for scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f742638-984c-49a8-b8da-4e8b59c62875",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame('-', ['score'], sfs_onehots.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de7a763-7417-4b1d-a594-40b1eb2c552b",
   "metadata": {},
   "source": [
    "##### insert scores into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3cae90-7261-4bf6-84ea-7ae795d17405",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in sfs_runs:                        # runs\n",
    "    for k in sfs_featdict[j]:             # steps within run\n",
    "        df_scores.loc['score',(j,k)] = sfs_scoredict[j][k]   \n",
    "df_scores = df_scores.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d152e306-0caf-43b6-b474-eff9b4c86b47",
   "metadata": {},
   "source": [
    "##### select the 5 multiindices that had the best cross-val scores across sffs and sfbs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3606234-2566-4adc-9455-c37ef9cec22b",
   "metadata": {},
   "source": [
    "##### cols_5best = df_scores.T.astype(float).nlargest(5, columns='score').T.columns\n",
    "scores_5best = df_scores.T.astype(float).nlargest(5, columns='score').values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe7f7ee-885f-4a7f-8510-61c0bc4ee6ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b9b9f53-e585-40f7-a160-61029a2513ef",
   "metadata": {},
   "source": [
    "##### use the indices to make a dataframe of onehots; then get lists of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bbeef7-a15b-4317-bad3-a3ffade8d412",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_5best_onehots = sfs_onehots[cols_5best].T.droplevel(level=0).reset_index(drop=True).T\n",
    "feats_5best = {}\n",
    "indices_5best = []\n",
    "for i in feats_5best_onehots.columns:\n",
    "    feats_5best[i] = set(feats_5best_onehots[i].loc[lambda x: x>0].index.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbb799b-b3b8-4dbc-8d24-10b402accfaa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Tune hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0616cb-fc13-42b3-81f2-a4a5f0dcb6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_featdict[2][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b98357-e6b5-4e98-becd-af4af79a5aba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_scores = {}\n",
    "best_Cs = {}\n",
    "for i in sfs_featdict:             # runs\n",
    "    test_scores[i] = {}\n",
    "    best_Cs[i] = {}\n",
    "    for j in sfs_featdict[i]:       # steps\n",
    "        lr_C = LogisticRegressionCV(penalty='l2', Cs=[.01,.1,1,10,100], max_iter=1000, fit_intercept=True)\n",
    "        lr_C.fit(Xtr[sfs_featdict[i][j]], ytr)\n",
    "        best_Cs[i][j] = lr_C.C_[0]\n",
    "        test_scores[i][j] = lr_C.score(Xte[sfs_featdict[i][j]], yte)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca364db-5e47-421e-9e3e-9789b4a1094c",
   "metadata": {},
   "source": [
    "#### Plot test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d221e18-188f-48e9-9ba4-a3b2961b021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(14,4))\n",
    "fig.subplots_adjust(wspace=.4)\n",
    "\n",
    "pd.Series(test_scores[2]).plot(ax=ax[0])\n",
    "pd.Series(test_scores[3]).plot(ax=ax[1])\n",
    "for axis in ax:\n",
    "    axis.set_xlabel('kfeats')\n",
    "    axis.set_ylabel('accuracy')\n",
    "ax[0].set_title('Sequential Floating Forward Selection')\n",
    "ax[1].set_title('Sequential Floating Backward Selection')\n",
    "fig.suptitle('Logistic Regression: Test-set accuracy scores for each feature set (baseline accuracy 0.5)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2770d2fd-1be6-48ed-b77d-75364be32228",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b572b1f4-4201-47d0-8034-56cfd816645c",
   "metadata": {},
   "source": [
    "#### Plot optimal C from LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cd5561-98cd-4000-8169-7a179073a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(14,4))\n",
    "fig.subplots_adjust(wspace=.4)\n",
    "\n",
    "pd.Series(best_Cs[2]).plot(ax=ax[0])\n",
    "pd.Series(best_Cs[3]).plot(ax=ax[1])\n",
    "for axis in ax:\n",
    "    axis.set_xlabel('kfeats')\n",
    "    axis.set_ylabel('accuracy')\n",
    "    axis.set_yscale('log')\n",
    "ax[0].set_title('Sequential Floating Forward Selection')\n",
    "ax[1].set_title('Sequential Floating Backward Selection')\n",
    "fig.suptitle('Logistic Regression: Validation-set accuracy scores for each feature set (baseline accuracy 0.5)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232acb13-3fa0-4932-b2b2-ff19ce5b39af",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ed751d-3bb1-4443-a784-3b60b0be7374",
   "metadata": {},
   "outputs": [],
   "source": [
    "scor_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905b9e76-5b77-40fb-b808-ae4500f14d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_Cs; # all best_Cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69a4699-8675-4a56-af4f-5ec353f53806",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores; # all scores on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f0f592-57f4-4688-9079-b3e630d92735",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_5best # best 5 cross-validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fed8b0-90e3-42dd-b882-abe75134d972",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pd.DataFrame(test_scores)\n",
    " .T\n",
    " .stack()\n",
    " .loc[cols_5best]\n",
    " .sort_index()\n",
    " .reset_index()\n",
    " .rename(columns={'level_0':'direction', 'level_1':'kfeats', 0:'test_accuracy'})\n",
    " .assign(direction=lambda x: x.direction.replace({2:'forward', 3:'backward'}))\n",
    " .assign(test_accuracy=lambda x: x.test_accuracy.round(3).astype(str))\n",
    " .style.set_caption(\"Best 5 Feature Selections by cv_score\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2baed30e-ede9-475b-8c4b-69e1ea803366",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_5best_onehots[0][feats_5best_onehots[0] > 0].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2837f7a-86c7-4d5f-baa3-ae0dac7885a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(map(len,feats_5best.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd187845-3da6-448b-b6f2-bc8108af1ace",
   "metadata": {},
   "source": [
    "### Choose a feature set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85044dd0-ef7e-4265-b117-96cb8af6a9dc",
   "metadata": {},
   "source": [
    "The 10-feature set had the best cross-val score and almost the best test score.  \n",
    "Its features are also a strict subset of three other top-5 sets, which may suggest lower variance.\n",
    "It was also optimized with a moderate regularization penalty.\n",
    "\n",
    "Choose the 10 feature set, and C=1.0. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352186ee-4267-4020-91e1-602804acdb50",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab21543-8752-4cef-93be-adf758b27214",
   "metadata": {},
   "source": [
    "- The smooth rising and falling of cross-val scores suggests a consistent bias-variance tradeoff\n",
    "- It's useful to see the curves for forwards and backwards, and the "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
