{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "315e258b-7258-48f2-b5ee-548258bd6456",
   "metadata": {},
   "source": [
    "# Predict hoax using scaled features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110011f9-0aaa-4b6c-9024-c1d2e7ac0bb6",
   "metadata": {},
   "source": [
    "Goal: Match or surpass the $R^2$ achieved with unscaled features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c439bdc-bf74-483e-b15f-a1d0fc6fba51",
   "metadata": {
    "tags": []
   },
   "source": [
    "### notes ~ only using regularization for feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1b27b7-f7c9-4360-a8d8-b01a017c3bea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### ➜ Fewer coefficients present without scaling. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa641e40-2262-43b5-a05b-e2b97513c29e",
   "metadata": {},
   "source": [
    "- There was a typo and a feature slipped through that wasn't supposed to\n",
    "    - ➜ fixed\n",
    "    - The sets are the same now, but the phenomenon is remaining.\n",
    "- Maybe it's because the intercept was scaled to zero?  \n",
    "    - ➜ Try only scaling the original floats.\n",
    "    - Score improved to .54/.5 , but unscaled remains .6\n",
    "- Look at (unscaled_coeff / $\\sigma$) to understand feature importance\n",
    "    - ➜ Try repeating the regression with these features only\n",
    "    - Score improved to .55/.5 , and unscaled remains .58\n",
    "- Checked Lasso (with all features)\n",
    "    - ➜ same results as Ridge: .54/.5\n",
    "- Relaxed my limitation of C,\n",
    "    - ➜ improved to .57/.5 with C=6\n",
    "- Ran logistic regression on unscaled features with no regularization\n",
    "    - ➜ improved to .61/.5\n",
    "    - Far out-performed the paper-author's models\n",
    "- Let's try SFS with scaled features\n",
    "    - Success!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d97848-f734-4c4d-9512-b28f1965ade5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## exploration controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff9a7a36-c1b5-4f81-8651-f50ac3fdeb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cf4c59-546e-453f-9aef-cce814551a91",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36311d5e-beb7-471f-a963-ed1f57c60242",
   "metadata": {
    "tags": []
   },
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "522dd10f-5501-4d60-b29c-3a857f23ba1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, patsy\n",
    "import pandas as pd, numpy as np\n",
    "from datetime import datetime as dt\n",
    "from sklearn.model_selection import train_test_split\n",
    "path = '/home/bhrdwj/git/predwikt/data/raw/wiki_reliability/unzipped/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c93dfd55-0405-4534-ad2d-db33b0b1de8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fea = (pd.read_csv(path+'hoax_features.csv', usecols=lambda x: x not in ['Unnamed: 0'])\n",
    "       .rename(columns={'headings_by_level(2)':'headings_by_level_2', 'revision_id.key':'revision_id_key'}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d507d75-7553-4319-9c39-d80baea4166f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f4b2da-0012-4cba-b7cb-d0f56e092dac",
   "metadata": {},
   "source": [
    "#### Make series of negative revisions and their revision keys, and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35f30aaf-6d36-4c06-a857-6b6b717e8514",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1390,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_revs = fea[['revision_id', 'revision_id_key', 'has_template']]\n",
    "neg_revs = neg_revs.loc[neg_revs.has_template==0].set_index('revision_id')['revision_id_key']\n",
    "pos_revs = fea[['revision_id', 'revision_id_key', 'has_template']]\n",
    "pos_revs = pos_revs.loc[pos_revs.has_template==1].set_index('revision_id')['revision_id_key']\n",
    "\n",
    "neg_revs.shape #, pos_revs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9cacc0-02a2-4289-938b-4777886cad99",
   "metadata": {},
   "source": [
    "#### Test-train split the neg_revs, and form dfte and dftr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cfa337d-351a-4842-9968-ba52d362d8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_revs_tr, neg_revs_te = train_test_split(neg_revs, test_size=.2, random_state=0)\n",
    "pos_revs_tr = pos_revs[neg_revs_tr.values]\n",
    "pos_revs_te = pos_revs[neg_revs_te.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6eed864-538d-45d7-a0e2-9b28d0f39c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "revs_tr = pd.concat((neg_revs_tr, pos_revs_tr))\n",
    "revs_te = pd.concat((neg_revs_te, pos_revs_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e863c433-eeda-44de-ac19-daffddb6e753",
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_rev = fea.set_index('revision_id')\n",
    "dftr = fea_rev.loc[revs_tr.index].dropna()\n",
    "dfte = fea_rev.loc[revs_te.index].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e831562-e1a0-449a-9a6d-7c29055d1e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "del neg_revs, pos_revs, neg_revs_tr, pos_revs_tr, neg_revs_te, pos_revs_te, revs_tr, revs_te, fea_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af05ed3d-dc88-46c9-8feb-54ceedd01393",
   "metadata": {},
   "outputs": [],
   "source": [
    "dftr[dftr.columns.difference(['page_id','revision_id_key','has_template'])].describe().T.sort_values(by='mean');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3973ad-4155-410f-96d4-2cf48761841f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cd82483-08e1-4b76-887e-0204310cddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non-features; onehotify categoricals\n",
    "ytr = dftr.has_template\n",
    "Xtr = dftr[dftr.columns.difference(['page_id','revision_id_key','has_template'])]\n",
    "Xtr = patsy.dmatrix('~ '+' + '.join(Xtr.columns), data=Xtr, NA_action='drop', return_type='dataframe')\n",
    "\n",
    "yte = dfte.has_template\n",
    "Xte = dfte[dfte.columns.difference(['page_id','revision_id_key','has_template'])]\n",
    "Xte = patsy.dmatrix('~ '+' + '.join(Xte.columns), data=Xte, NA_action='drop', return_type='dataframe')\n",
    "\n",
    "# make complete list of columns in case the test set doesn't include any of a rare class\n",
    "Xcols = list(\n",
    "    set(Xtr.columns.tolist())\n",
    "    .union(set(Xte.columns.tolist()))\n",
    ")\n",
    "\n",
    "for col in Xcols:\n",
    "    if col not in Xte:\n",
    "        Xte[col] = 0\n",
    "    if col not in Xtr:\n",
    "        Xtr[col] = 0\n",
    "        \n",
    "Xtr = Xtr.reindex(columns=Xcols)\n",
    "Xte = Xte.reindex(columns=Xcols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bec3c2f5-377a-4b55-b678-79991bfd5798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2221, 25), (556, 25))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtr.shape, Xte.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f6a440-8c88-4fed-9322-2c6a1bd15f31",
   "metadata": {},
   "source": [
    "## pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea08c21d-7ac3-4a06-93ae-0ca2a9af3fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a071b3-a292-42fb-8209-804426ede9b0",
   "metadata": {},
   "source": [
    "## Custom gridsearch for feature & hyperparameter selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d04692c-87c0-4865-ac23-e0397daf263e",
   "metadata": {},
   "source": [
    "### When to use sklearn's GridSearchCV to wrap SFS?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a21a189-89aa-413a-8d80-2d165fc18057",
   "metadata": {},
   "source": [
    "- Technical particularity:\n",
    "    - It's only possible to get access to the SFS instance for the param combination that GridSearchCV found to be optimal.\n",
    "    - This mitigates output complexity, but prevents thorough review.\n",
    "    - It would prevent a review of both SFFS and SFBS within the same gridsearch as is done here, for instance.\n",
    "- Pros\n",
    "    - GridSearchCV is great for automated production applications, to make the code robust, concise, and palatable for other users.\n",
    "- Cons\n",
    "    - GridSearchCV wouldn't let me do a viz overview of the param_grid outputs.\n",
    "    - (it's grid ***search***, not grid ***exploration***.) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a48f9d4-609e-4767-bf01-55fc6b1c758c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### Previous thoughts on why not to use sklearn's GridSearchCV with SFS:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc692f22-5ff7-4462-a755-49357f69146c",
   "metadata": {},
   "source": [
    "sklearn.model_selection.GridSearchCV can only optimize one hyperparameter at a time. It cannot require two hyperparameters to be fixed together.  \n",
    "However to implement SFS in a pipeline with GridSearchCV requires two instances of the estimator:\n",
    "\n",
    "- one instance est_sfs for the estimator in SFS, and \n",
    "- another instance est_scor at the end of the pipeline to allow it to be used to fit a model.\n",
    "\n",
    "But then, these two estimator instances will have two separate/parallel sets of hyperparameters. \n",
    "\n",
    "Consider that the model used for these instances is sklearn.linear_model.LogisticRegression, which has a regularization hyperparameter C.  \n",
    "The C used by the LogisticRegression inside SFS is used to select features, and the C at the end of the pipeline is used by the gridsearch to score each model run.  \n",
    "\n",
    "Three solution alternatives to make sure the two C's are the same for each model run:\n",
    "1. Use GridSearch to wrap the pipeline and param_grid, with an unused stand-in estimator at the end of the pipeline. Write a custom function to analyze and score the SFS output pulled directly from my_pipeline.steps[index] etc.\n",
    "2. Write my own custom gridsearch function.\n",
    "3. Rewrite the GridSearchCV code as was done in this SOF answer (without fully-posted code)\n",
    "\n",
    "documentation here ([link](https://stackoverflow.com/questions/48831851/how-to-pass-two-estimator-objects-to-sklearns-gridsearchcv-so-that-they-have-th))\n",
    "\n",
    "Another perspective:\n",
    "- Maybe doing the scoring with a different estimator est_scor is better:\n",
    "    - The main point of a diverse paramgrid within SFS is develop a diverse output of feature sets.\n",
    "    - That's an entirely separate goal from tuning optimal hyperparameters for the final model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e240ab32-e6c4-4444-b038-4e22ebc59adf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47998023-f505-442c-97d1-f9e3832dc3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db08091b-4858-4ac7-aa39-67da06882fd5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### not using it rn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab9c05f-655c-4687-bded-b2c80d50f220",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### line-by-line of function"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b11acdae-abcd-4942-b25f-d4b6807a7f7d",
   "metadata": {},
   "source": [
    "param_grid = sfs_pipe_param_grid\n",
    "\n",
    "print(f'start time: {dt.now()}')\n",
    "pg = {i:j for i,j in enumerate(ParameterGrid(param_grid), start=1)}\n",
    "sfs_featdict = {}\n",
    "for i in pg:\n",
    "    pipe.set_params(**pg[i]).fit(Xtr, ytr)\n",
    "    k_feats = pg[i]['sfs__k_features']\n",
    "    idx_tup = pipe.steps[-1][1].get_metric_dict()[k_feats]['feature_idx']\n",
    "    sfs_featdict[i] = {k:list(v['feature_idx']) for k,v in pipe.steps[1][1].subsets_.items()}  # change pipe.steps[1] to directly look for the sfs ste\n",
    "    # Xtr.iloc[:,list(idx_tup)].columns.tolist()\n",
    "print(f'finish time: {dt.now()}')\n",
    "sfs_featdict;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34e1448-5d8e-46e9-91ce-78573656549b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### remove duplicate featuresets"
   ]
  },
  {
   "cell_type": "raw",
   "id": "980067a1-7900-42df-83ae-85026ed61c4d",
   "metadata": {},
   "source": [
    "sfs_set = set()\n",
    "for key,value in sfs_dict.items():\n",
    "    if frozenset(value) not in sfs_set:\n",
    "        sfs_set.add(frozenset(value))\n",
    "sfs_list = sorted(list(sfs_set), key=len)\n",
    "sfs_dict = {i:tuple(s) for i,s in enumerate(sfs_list, start=1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970e8025-1fdc-4c1c-9f25-e8b9c844114e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c46fcb-9c46-415b-b2bc-1caaa0f589fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### get_fitfeats_sfs_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ad3492f-bc9f-4139-a639-c4911599779f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fitfeats_sfs_pipe(Xtr, ytr, pipe, param_grid:dict):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        Xtr: pd.DataFrame of features\n",
    "        ytr: pd.Series target\n",
    "        pipe: sklearn Pipeline ending in a mlxtend SequentialFeatureSelector instance.\n",
    "        param_grid: dict of lists, params of pipe, input for sklearn ParameterGrid\n",
    "    Returns:\n",
    "        dict:\n",
    "        - keys are numbers starting in 1, for each cell of ParameterGrid\n",
    "        - values are lists of feature names\n",
    "    \"\"\"\n",
    "    print(f'start time: {dt.now()}')\n",
    "    pg = {i:j for i,j in enumerate(ParameterGrid(param_grid), start=1)}\n",
    "    sfs_featdict = {}\n",
    "    sfs_scoredict = {}\n",
    "    for i in pg:\n",
    "        pipe.set_params(**pg[i]).fit(Xtr, ytr)\n",
    "        k_feats = pg[i]['sfs__k_features']\n",
    "        idx_tup = pipe.steps[-1][1].get_metric_dict()[k_feats]['feature_idx']\n",
    "        \n",
    "        d = {k:list(v['feature_idx']) for k,v in pipe.steps[1][1].subsets_.items()}  # IMPROVEMENT: change pipe.steps[1] to directly look for the sfs step\n",
    "        for j in d: d[j] = Xtr.columns[d[j]]\n",
    "        sfs_featdict[i] = d\n",
    "        \n",
    "        s = {k:v['avg_score'] for k,v in pipe.steps[1][1].subsets_.items()} # IMPROVEMENT: change pipe.steps[1] to directly look for the sfs step\n",
    "        sfs_scoredict[i] = s\n",
    "    print(f'finish time: {dt.now()}')\n",
    "    return sfs_featdict, sfs_scoredict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b455e5-00a7-435f-a71b-32d868985069",
   "metadata": {
    "tags": []
   },
   "source": [
    "### instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0eab8d0-f6c1-4aa8-892c-3568fc7bc626",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "lr_sfs = LogisticRegression(penalty='l2', max_iter=1000, fit_intercept=True)\n",
    "sfs = SFS(estimator=lr_sfs, forward=True, floating=False, scoring='accuracy', cv=5)\n",
    "sffs = SFS(estimator=lr_sfs, forward=True, floating=True, scoring='accuracy', cv=5)\n",
    "sfbs = SFS(estimator=lr_sfs, forward=False, floating=True, scoring='accuracy', cv=5)\n",
    "sfs_pipe = Pipeline([('scaler', scaler),('sfs', sfs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bde31d-f823-4c71-8529-8cabea8cd79e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0c7045-80ac-4492-9a44-ead915eeada2",
   "metadata": {},
   "source": [
    "#### sffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5b38a34-eece-4fee-bb22-b62dc7d6749e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2021-12-29 18:45:23.100532\n",
      "finish time: 2021-12-29 18:48:23.380889\n"
     ]
    }
   ],
   "source": [
    "sfs_pipe_param_grid = {\n",
    "    'sfs': [sffs, sfbs],\n",
    "    'sfs__k_features': [1, len(Xtr.columns)],\n",
    "    'sfs__estimator__C': [.1]\n",
    "}\n",
    "\n",
    "sfs_featdict, sfs_scoredict = get_fitfeats_sfs_pipe(Xtr, ytr, sfs_pipe, sfs_pipe_param_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8deb71-fd2e-4445-a1d9-65c06204dd1f",
   "metadata": {},
   "source": [
    "## To put into the functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76649321-4416-4531-8a69-7bd4d125965a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### extract feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0b6478-e6a7-423c-b754-8d10e643c801",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### get onehot df ~ features selected by sfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e5e94c-a99f-4ac7-8962-81fc1c9f862d",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### munge_onehotdf_from_sfs_featdict (function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6438af4-ad74-4700-818f-42821419e881",
   "metadata": {},
   "outputs": [],
   "source": [
    "def munge_onehotdf_from_sfs_featdict(sfs_featdict):\n",
    "    \n",
    "    # simple 1D list of sfs  feats\n",
    "    sfs_feat_set = set()\n",
    "    for i in sfs_featdict:              # runs\n",
    "        for j in sfs_featdict[i]:       # kfeats\n",
    "            sfs_feats = list(sfs_feat_set.union(set(sfs_featdict[i][j])))\n",
    "    \n",
    "    # make multiindex columns and empty dataframe\n",
    "    col = pd.MultiIndex.from_tuples(\n",
    "        [(j,k) for j in sfs_featdict for k in sfs_featdict[j]])\n",
    "    idx = pd.Index(sfs_feats, name='feature')\n",
    "    df = pd.DataFrame('-', idx, col)\n",
    "    \n",
    "    # insert onehots into df\n",
    "    for i in sfs_feats:                           # feats\n",
    "        for j in sfs_featdict:                        # runs\n",
    "            for k in sfs_featdict[j]:             # steps within run\n",
    "                df.loc[i,(j,k)] = int(i in sfs_featdict[j][k])\n",
    "    \n",
    "    df = df.astype(int) \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0481c26e-a80e-4b34-83e3-9e001f6c5bff",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### get df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa0e9a69-35be-42e9-a7a5-80af854e688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_onehots = munge_onehotdf_from_sfs_featdict(sfs_featdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bab933-3331-433a-b1be-58970b393f5b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### get simple 1D lists of sfs runs, kfeats, and feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3a653fc4-e071-45ab-a72a-9a11399de70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_runs = list(sfs_featdict.keys())\n",
    "\n",
    "sfs_feat_set, sfs_kfeats_set = set(), set()\n",
    "for i in sfs_featdict:              # runs\n",
    "    for j in sfs_featdict[i]:       # kfeats\n",
    "        sfs_feats = list(sfs_feat_set.union(set(sfs_featdict[i][j])))\n",
    "        sfs_kfeats = list(sfs_kfeats_set.union(set([j])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecc3f6a-425c-4523-a38f-41457d5b7f39",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### sort the index of features by occurence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6264fc-ec95-45cf-9832-47c8ce364b9f",
   "metadata": {},
   "source": [
    "##### count occurrences of features to sort the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f3557054-1dbd-45a6-b848-98c625bda276",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = pd.IndexSlice\n",
    "sfs_feat_usecounts = sfs_onehots.loc[:,idx[1,:]].sum(axis=1)\n",
    "for i in range(2,5):\n",
    "    sfs_feat_usecounts += sfs_onehots.loc[:,idx[i,:]].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee0f850-416d-45eb-a86c-7d498f330d4e",
   "metadata": {},
   "source": [
    "##### sort features by frequency of occurence in sfs cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "122e3844-82c9-43bc-ac47-1af518b1cfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs_onehots = sfs_onehots.reindex(index=sfs_feat_usecounts.sort_values(ascending=False).index)\n",
    "sfs_onehots = sfs_onehots.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9a46d1-6b4d-4823-bf7e-54ccde89d43e",
   "metadata": {},
   "source": [
    "### visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22fb8d7-ff69-4a1f-91db-a8f8be9f7c4e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55c2f385-0a14-4870-92a1-c2b7358002a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.use('TkAgg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b2c4ff4-c49f-48d2-8750-4f74ed9d1ddd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### plot feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cac95e0d-935d-413d-a020-6a09ba4816cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(14,8))\n",
    "fig.subplots_adjust(wspace=.6)\n",
    "\n",
    "(sns.heatmap(\n",
    "    sfs_onehots.loc[:,idx[2,:]].T.droplevel(level=0).T, \n",
    "    ax=ax[0], cbar=False)\n",
    "    .set(ylabel=None, xlabel='kfeats')   \n",
    ")\n",
    "(sns.heatmap(\n",
    "    sfs_onehots.loc[:,idx[3,:]].T.droplevel(level=0).T, \n",
    "    ax=ax[1], cbar=False)\n",
    "    .set(ylabel=None, xlabel='kfeats')\n",
    ")\n",
    "\n",
    "ax[0].set_title('Sequential Floating Forward Selection')\n",
    "ax[1].set_title('Sequential Floating Backward Selection')\n",
    "fig.suptitle('Logistic Regression: Features selected, graphed against k_features')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a237947-1b3f-4f53-ba4f-c731b1a2bc61",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### plot scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3d2c512-3dde-49ac-b514-8a30dc24bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(14,4))\n",
    "fig.subplots_adjust(wspace=.4)\n",
    "\n",
    "pd.Series(sfs_scoredict[2]).plot(ax=ax[0])\n",
    "pd.Series(sfs_scoredict[3]).plot(ax=ax[1])\n",
    "for axis in ax:\n",
    "    axis.set_xlabel('kfeats')\n",
    "    axis.set_ylabel('accuracy')\n",
    "ax[0].set_title('Sequential Floating Forward Selection')\n",
    "ax[1].set_title('Sequential Floating Backward Selection')\n",
    "fig.suptitle('Logistic Regression: Cross-validation accuracy score from SFS (baseline accuracy 0.5)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d98921-668e-46ae-aae3-dbd54416f770",
   "metadata": {},
   "source": [
    "#### Get top 5 feats sets by cross-val score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283d1720-d935-4df8-8045-7a6ac4e0aba4",
   "metadata": {},
   "source": [
    "##### create empty dataframe for scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f742638-984c-49a8-b8da-4e8b59c62875",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scores = pd.DataFrame('-', ['score'], sfs_onehots.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de7a763-7417-4b1d-a594-40b1eb2c552b",
   "metadata": {},
   "source": [
    "##### insert scores into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b3cae90-7261-4bf6-84ea-7ae795d17405",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in sfs_runs:                        # runs\n",
    "    for k in sfs_featdict[j]:             # steps within run\n",
    "        df_scores.loc['score',(j,k)] = sfs_scoredict[j][k]   \n",
    "df_scores = df_scores.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d152e306-0caf-43b6-b474-eff9b4c86b47",
   "metadata": {},
   "source": [
    "##### select the 5 multiindices that had the best cross-val scores across sffs and sfbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7141636f-6c67-4456-96ca-68b52a1e39f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_5best = df_scores.T.astype(float).nlargest(5, columns='score').T.columns\n",
    "scores_5best = df_scores.T.astype(float).nlargest(5, columns='score').values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9b9f53-e585-40f7-a160-61029a2513ef",
   "metadata": {},
   "source": [
    "##### use the indices to make a dataframe of onehots; then get lists of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "76bbeef7-a15b-4317-bad3-a3ffade8d412",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_5best_onehots = sfs_onehots[cols_5best].T.droplevel(level=0).reset_index(drop=True).T\n",
    "feats_5best = {}\n",
    "for i in feats_5best_onehots.columns:\n",
    "    feats_5best[i] = set(feats_5best_onehots[i].loc[lambda x: x>0].index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05d55ecb-0eb9-4840-95d4-e3f3a90a40b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_5best;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbb799b-b3b8-4dbc-8d24-10b402accfaa",
   "metadata": {},
   "source": [
    "#### tune hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9b98357-e6b5-4e98-becd-af4af79a5aba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_Cs = {}\n",
    "test_scores = {}\n",
    "for i in feats_5best:\n",
    "    lr_C = LogisticRegressionCV(penalty='l2', Cs=[.01,.1,1,10,100], max_iter=1000, fit_intercept=True)\n",
    "    lr_C.fit(Xtr[feats_5best[i]], ytr)\n",
    "    best_Cs[i] = lr_C.C_[0]\n",
    "    test_scores[i] = lr_C.score(Xte[feats_5best[i]], yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "905b9e76-5b77-40fb-b808-ae4500f14d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0, 1: 100.0, 2: 0.01, 3: 0.01, 4: 10.0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_Cs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f69a4699-8675-4a56-af4f-5ec353f53806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 0.6115107913669064,\n",
       "  1: 0.6079136690647482,\n",
       "  2: 0.5989208633093526,\n",
       "  3: 0.6187050359712231,\n",
       "  4: 0.5935251798561151},\n",
       " [[0.6271910112359551],\n",
       "  [0.6267395485373013],\n",
       "  [0.6262931470796639],\n",
       "  [0.625840672132807],\n",
       "  [0.6258396598846038]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scores, scores_5best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2837f7a-86c7-4d5f-baa3-ae0dac7885a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, 14, 8, 13, 11]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(len,feats_5best.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd187845-3da6-448b-b6f2-bc8108af1ace",
   "metadata": {},
   "source": [
    "### Choose a feature set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85044dd0-ef7e-4265-b117-96cb8af6a9dc",
   "metadata": {},
   "source": [
    "The 10-feature set had the best cross-val score and the best test score.  \n",
    "Its features are also a strict subset of three other top-5 sets, which may suggest lower variance.\n",
    "It was also optimized with a moderate regularization penalty.\n",
    "\n",
    "Choose the 10 feature set, and C=1.0. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
