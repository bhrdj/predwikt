{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48660241-8117-4a73-b0b4-df969997b4ec",
   "metadata": {},
   "source": [
    "# get pageviews with AWS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efed6e0",
   "metadata": {},
   "source": [
    "#### how to do jupyter with aws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b3ed43",
   "metadata": {},
   "source": [
    "- https://dataschool.com/data-modeling-101/running-jupyter-notebook-on-an-ec2-server/\n",
    "    - except jupyter_notebook_config.py_ should be ...config.py instead\n",
    "- https://gist.github.com/J535D165/0e840291e7b2598ec157e13e9b9ca569\n",
    "    - trying this for how to use nohup\n",
    "- some medium [article](https://medium.com/@christinakouride/a-beginners-guide-to-running-jupyter-notebook-on-amazon-ec2-69e1b74e73cc#:~:text=Your%20Jupyter%20Notebook%20server%20will,for%20time%20not%20using%20it.)\n",
    "    - they pointed out that notebook will keep running, but didn't mention nohup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "17eba2f0-f33b-40f6-ae44-30c348ca5a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, gzip, pickle, io\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import mysql.connector as mysql, sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c9239c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.7\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac72715f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcf8b3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mysql_user = 'ubuntu'\n",
    "# mysql_pass = input(f'Enter the MySQL password for user {mysql_user}: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c839ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_mariadb():\n",
    "    host='localhost'; user=mysql_user; passwd=mysql_pass; dbname='jawiki';\n",
    "    cxn = mysql.connect(host=host,user=user,passwd=passwd, database=dbname)\n",
    "    cur = cxn.cursor()\n",
    "\n",
    "    connection_str = 'mysql+mysqlconnector://'+user+':'+passwd+'@'+host+'/'+dbname  # removed this after host +':'+dbport\n",
    "    try:\n",
    "        engine = sqlalchemy.create_engine(connection_str)\n",
    "        conn = engine.connect()\n",
    "    except Exception as e:\n",
    "        print('Database connection error - check creds')\n",
    "        print(e)\n",
    "    return cxn, cur, engine, conn\n",
    "        \n",
    "cxn, cur, engine, conn = connect_mariadb()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2abe8c",
   "metadata": {},
   "source": [
    "## get page_titles and urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de008d3e",
   "metadata": {},
   "source": [
    "###### unpickle page list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7388cd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/processed/jawiki/' + 'disaster_descendants_raw.pickle', 'rb') as f:\n",
    "    disaster_descendants_raw = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36841335",
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_cat_page_ids = {'火山災害':2390743, '熱帯低気圧':626482, '雪害':2390774, '地震':135264, '津波':765772}  # '自然災害':137069, \n",
    "disasters_english = {'火山災害':'VolcanicDisaster', '熱帯低気圧':'TropicalCyclones', '雪害':'SnowDamage', '地震':'Earthquake', '津波':'Tsunami'}\n",
    "disasters = list(disaster_cat_page_ids.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14330555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def failed_decode(a):\n",
    "    try:\n",
    "        a.decode('utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def bytearray_to_str(a:bytearray, encoding='utf-8') -> str:\n",
    "    if type(a) != bytearray:\n",
    "        return a        \n",
    "    while failed_decode(a):\n",
    "        a = a[:-1]\n",
    "    return str(a.decode(encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f98174eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i in disaster_descendants_raw:\n",
    "    d[i] = (disaster_descendants_raw[i]\n",
    "            .drop_duplicates(subset='id')\n",
    "            .applymap(bytearray_to_str)\n",
    "           )\n",
    "    d[i] = d[i][d[i].namespace == 0]\n",
    "    d[i]['page_title'] = d[i].name.map(lambda x: str(x).split(sep='\\n')[-1])\n",
    "disaster_descendants = d\n",
    "del d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da794417",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_titles = [j for i in disaster_descendants for j in disaster_descendants[i].page_title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b3f2c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "f6ec5f60",
   "metadata": {},
   "source": [
    "for i in disaster_descendants:\n",
    "    print(i)\n",
    "    print(disaster_descendants[i][disaster_descendants[i].page_title.isin(['WHITEBERRY'])])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "98201db6",
   "metadata": {},
   "source": [
    "disaster_descendants['火山災害'][disaster_descendants['火山災害'].page_title.isin(['WHITEBERRY'])]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fd7d91de",
   "metadata": {},
   "source": [
    "all_titles[5444:5470]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6abc9742",
   "metadata": {},
   "source": [
    "[i for i in all_titles if i == 'WHITEBERRY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee994dc",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899ddcee-6006-4aa1-9219-877a34704748",
   "metadata": {},
   "source": [
    "##### function download_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1d5b0f9-df90-4710-8349-543a9723c17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url, dirpath='./'):\n",
    "    local_filepath = dirpath + url.split('/')[-1]\n",
    "    # NOTE the stream=True parameter below\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(local_filepath, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=131072):   #8192\n",
    "                # If you have chunk encoded response uncomment if\n",
    "                # and set chunk_size parameter to None.\n",
    "                #if chunk: \n",
    "                f.write(chunk)\n",
    "    return local_filepath\n",
    "# https://stackoverflow.com/questions/16694907/download-large-file-in-python-with-requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8b2b41",
   "metadata": {},
   "source": [
    "###### function ```open_hour_file``` to provide the unzipped file to python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0bca7d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_hour_file(path:str):\n",
    "    if path[-3:] == \".gz\":\n",
    "        return gzip.open(path, mode=\"rt\", encoding=\"utf-8\", errors=\"replace\")\n",
    "    else:\n",
    "        return open(path, mode=\"rt\", encoding=\"utf-8\", errors=\"replace\")\n",
    "# https://github.com/mediawiki-utilities/python-mwviews/blob/main/src/mwviews/utilities/aggregate.py\n",
    "# https://stackoverflow.com/questions/30582162/creating-a-missing-directory-file-structure-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d09626",
   "metadata": {},
   "source": [
    "###### function subset_pageviews_by_project to get all jawiki pageviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "121f77c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_time_from_filename(filename:str):\n",
    "    [d, t] = filename.split('-')[1:]\n",
    "    return dt.datetime(int(d[:4]), int(d[4:6]), int(d[6:]), int(t[:2]), tzinfo=dt.timezone.utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d1336514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pageviews_subset_by_project(fpath_in, proj:str='ja', ) -> pd.DataFrame:\n",
    "    lst = []\n",
    "    colnames=['domain_code','page_title','count_views','total_response_size']\n",
    "    # subset pageview records by project as list of strings\n",
    "    with open_hour_file(fpath_in) as f_in:\n",
    "        while (line := f_in.readline()):\n",
    "            if line[:3] != proj + ' ':\n",
    "                continue\n",
    "            lst.append(line)\n",
    "    # turn list of strings into dataframe\n",
    "    df = pd.read_csv(\n",
    "        io.StringIO('\\n'.join(lst))\n",
    "        ,delim_whitespace=True\n",
    "        ,names=colnames)\n",
    "    # add datetime as column based on filename\n",
    "    parsed_datetime = parse_time_from_filename(fpath_in.split(sep='/')[-1])\n",
    "    df = df.assign(datetime_viewed_UTC=parsed_datetime)\n",
    "    now_datetime = dt.datetime.now(tz=dt.timezone.utc)\n",
    "    df = df.assign(datetime_added_UTC=now_datetime)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fcc7565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_pageviews_subset_by_project(out_dirpath + 'pageviews-20210101-000000.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "aa2822ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql(name='pageviews',con=conn, if_exists='replace', flavor='mysql')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3b8baf9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field</th>\n",
       "      <th>Type</th>\n",
       "      <th>Null</th>\n",
       "      <th>Key</th>\n",
       "      <th>Default</th>\n",
       "      <th>Extra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>index</td>\n",
       "      <td>bigint(20)</td>\n",
       "      <td>YES</td>\n",
       "      <td>MUL</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>domain_code</td>\n",
       "      <td>text</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>page_title</td>\n",
       "      <td>text</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>count_views</td>\n",
       "      <td>bigint(20)</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>total_response_size</td>\n",
       "      <td>bigint(20)</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>datetime_viewed_UTC</td>\n",
       "      <td>timestamp</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>datetime_added_UTC</td>\n",
       "      <td>timestamp</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Field        Type Null  Key Default Extra\n",
       "0                index  bigint(20)  YES  MUL    None      \n",
       "1          domain_code        text  YES         None      \n",
       "2           page_title        text  YES         None      \n",
       "3          count_views  bigint(20)  YES         None      \n",
       "4  total_response_size  bigint(20)  YES         None      \n",
       "5  datetime_viewed_UTC   timestamp  YES         None      \n",
       "6   datetime_added_UTC   timestamp  YES         None      "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql('desc pageviews;', con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d6361a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain_code</th>\n",
       "      <th>page_title</th>\n",
       "      <th>count_views</th>\n",
       "      <th>total_response_size</th>\n",
       "      <th>datetime_viewed_UTC</th>\n",
       "      <th>datetime_added_UTC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ja</td>\n",
       "      <td>Hello,_world.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2022-03-20 07:04:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ja</td>\n",
       "      <td>$百萬BABY</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2022-03-20 07:04:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ja</td>\n",
       "      <td>'81秋・全番組総出演!激唱!!オールスター</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2022-03-20 07:04:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ja</td>\n",
       "      <td>(ry</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2022-03-20 07:04:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ja</td>\n",
       "      <td>+Lhaca</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2022-03-20 07:04:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ja</td>\n",
       "      <td>-</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2022-03-20 07:04:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ja</td>\n",
       "      <td>.260レミントン</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2022-03-20 07:04:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ja</td>\n",
       "      <td>.300ウィンチェスター・ショート・マグナム</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2022-03-20 07:04:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ja</td>\n",
       "      <td>.308ウィンチェスター</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2022-03-20 07:04:24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ja</td>\n",
       "      <td>.338ラプア・マグナム</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2022-03-20 07:04:24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      domain_code              page_title  count_views  total_response_size  \\\n",
       "index                                                                         \n",
       "0              ja           Hello,_world.            1                    0   \n",
       "1              ja                 $百萬BABY            1                    0   \n",
       "2              ja  '81秋・全番組総出演!激唱!!オールスター            1                    0   \n",
       "3              ja                     (ry            1                    0   \n",
       "4              ja                  +Lhaca            1                    0   \n",
       "5              ja                       -          138                    0   \n",
       "6              ja               .260レミントン            1                    0   \n",
       "7              ja  .300ウィンチェスター・ショート・マグナム            2                    0   \n",
       "8              ja            .308ウィンチェスター            1                    0   \n",
       "9              ja            .338ラプア・マグナム            1                    0   \n",
       "\n",
       "      datetime_viewed_UTC  datetime_added_UTC  \n",
       "index                                          \n",
       "0              2021-01-01 2022-03-20 07:04:24  \n",
       "1              2021-01-01 2022-03-20 07:04:24  \n",
       "2              2021-01-01 2022-03-20 07:04:24  \n",
       "3              2021-01-01 2022-03-20 07:04:24  \n",
       "4              2021-01-01 2022-03-20 07:04:24  \n",
       "5              2021-01-01 2022-03-20 07:04:24  \n",
       "6              2021-01-01 2022-03-20 07:04:24  \n",
       "7              2021-01-01 2022-03-20 07:04:24  \n",
       "8              2021-01-01 2022-03-20 07:04:24  \n",
       "9              2021-01-01 2022-03-20 07:04:24  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql('select * from pageviews limit 10;', con=conn, index_col='index')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e692e",
   "metadata": {},
   "source": [
    "###### function pageviews_to_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9f56bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pageviews_to_sql(df:pd.DataFrame, conn):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ed87e8",
   "metadata": {},
   "source": [
    "## get the files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589bf180",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "323da1ef",
   "metadata": {},
   "source": [
    "###### get many urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6383c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "'https://dumps.wikimedia.org/other/pageviews/2021/2021-01/pageviews-20210101-000000.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "382a0755",
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = list(range(2021,2022))\n",
    "hour_strings = list(map(lambda x: str(x).zfill(2), range(0,24)))\n",
    "dates = pd.date_range(dt.datetime(ys[0],1,1), \n",
    "                      end=dt.datetime(ys[-1]+1,1,1), \n",
    "                      freq='D')  # , tz='Japan'\n",
    "hs = map(lambda x: str(x).zfill(2), range(0,24))\n",
    "base_url = 'https://dumps.wikimedia.org/other/pageviews/'\n",
    "out_dirpath = '../data/processed/pageviews/'\n",
    "\n",
    "urls = [f'{base_url}{d.year}/{d.year}-{str(d.month).zfill(2)}'\n",
    "        f'/pageviews-{d.year}{str(d.month).zfill(2)}{str(d.day).zfill(2)}-{h}0000.gz'\n",
    "        for d in dates for h in hour_strings]\n",
    "outpaths = [f'{out_dirpath}{d.year}/{d.year}-{str(d.month).zfill(2)}'\n",
    "        f'/pageviews-{d.year}{str(d.month).zfill(2)}{str(d.day).zfill(2)}-{h}0000.txt'\n",
    "        for d in dates for h in hour_strings]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb49b531",
   "metadata": {},
   "source": [
    "##### populate the database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b76a9a8",
   "metadata": {},
   "source": [
    "###### test to_sql"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9c8dfc3e",
   "metadata": {},
   "source": [
    "out_dirpath+'pageviews-20210101-000000.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36972e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_fpath = download_file(url=urls[0], dirpath=out_dirpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c70b94",
   "metadata": {},
   "source": [
    "###### get a page_title-filtered hourfile from txt as a dataframe"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fdc7640c",
   "metadata": {},
   "source": [
    "pd.read_csv(out_dirpath+'test.txt', sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb01131",
   "metadata": {},
   "source": [
    "###### get a project-filtered  hourfile as txt, then df, then mariadb table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f226f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_pageviews_by_project(temp_fpath,out_dirpath+'test2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a285bca2",
   "metadata": {},
   "source": [
    "###### pageviews as df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f1618b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(out_dirpath+'test2.txt', sep=' ', \n",
    "                 names=['domain_code','page_title','count_views','total_response_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "881b4e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_time = dt.datetime(2021,1,1,0,0, tzinfo=dt.timezone.utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6c3cc55f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed60793e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce74640b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2651ba1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "f4d19b17",
   "metadata": {},
   "source": [
    "process_start_time = datetime.datetime.now()\n",
    "hours_in_year = 365*24\n",
    "count = 0\n",
    "for url, outpath in zip(urls, outpaths):\n",
    "    file_start_time = datetime.datetime.now()\n",
    "    temp_fpath = download_file(url, dirpath=temp_dirpath)\n",
    "    subset_pageviews_by_page_titles(temp_fpath,outpath,all_titles)\n",
    "    file_end_time = datetime.datetime.now()\n",
    "    clear_output(wait=True)\n",
    "    count += 1\n",
    "    print(outpath)\n",
    "    print(f'process time so far: {file_end_time - start_time}')\n",
    "    frac_done = max(count / hours_in_year, .0000001)\n",
    "    print(f'fraction done: {frac_done}')\n",
    "    process_time_so_far = dt.now() - process_start_time\n",
    "    finish_time = process_start_time + process_time_so_far / frac_done\n",
    "    print (f'expected finish time: {finish_time}')\n",
    "    os.remove(temp_fpath) # i forgot this the first time, it screwed me!\n",
    "process_end_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d52a68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a492b8e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ab5383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675b3826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d237a02d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "3262b130",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../data/processed/pageviews/2021/2021-01/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6960d79",
   "metadata": {},
   "source": [
    "##### download many files (OBSOLETE, SWITCHING TO MARIADB ON EC2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "816398fe",
   "metadata": {},
   "source": [
    "process_start_time = datetime.datetime.now()\n",
    "hours_in_year = 365*24\n",
    "count = 0\n",
    "for url, outpath in zip(urls, outpaths):\n",
    "    file_start_time = datetime.datetime.now()\n",
    "    temp_fpath = download_file(url, dirpath=temp_dirpath)\n",
    "    subset_pageviews_by_page_titles(temp_fpath,outpath,all_titles)\n",
    "    file_end_time = datetime.datetime.now()\n",
    "    clear_output(wait=True)\n",
    "    count += 1\n",
    "    print(outpath)\n",
    "    print(f'process time so far: {file_end_time - start_time}')\n",
    "    frac_done = max(count / hours_in_year, .0000001)\n",
    "    print(f'fraction done: {frac_done}')\n",
    "    process_time_so_far = dt.now() - process_start_time\n",
    "    finish_time = process_start_time + process_time_so_far / frac_done\n",
    "    print (f'expected finish time: {finish_time}')\n",
    "    os.remove(temp_fpath) # i forgot this the first time, it screwed me!\n",
    "process_end_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d795070c",
   "metadata": {},
   "source": [
    "###### peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd1e8c6-edfe-4e9d-94b5-47806c072bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to script '1.22-sfb-get-pageviews-with-AWS-lambda.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426c5806-a843-43a0-a655-a776e8fe2f49",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "##### -----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d36be5-731b-419b-93f7-8119a95682d4",
   "metadata": {},
   "source": [
    "###### ------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdac068",
   "metadata": {},
   "source": [
    "##### test running cell while laptop sleeping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4629d60",
   "metadata": {},
   "source": [
    "###### idea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018ec808",
   "metadata": {},
   "source": [
    "- consider the case where:\n",
    "    - i start the following cell's script as follows:\n",
    "        - on AWS from a ssh terminal \n",
    "        - via nohup jupyter on computer A\n",
    "    - then i disconnect the ssh from computer A\n",
    "        - so that the cell is still running in the instance\n",
    "- then i find the result that:\n",
    "    - i can reopen jupyter from another ssh terminal\n",
    "    - i can interrupt the script\n",
    "    - but i can't see its in-process results\n",
    "- strategy for now:\n",
    "    - develop the script on whatever computers\n",
    "    - then run it from a browser tab in my android phone\n",
    "        - that way i can keep \"tabs\" on it (😉)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb29c376",
   "metadata": {},
   "source": [
    "###### test code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2af2ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "for i in range(600):\n",
    "    print(i)\n",
    "    time.sleep(1)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7b7f63",
   "metadata": {},
   "source": [
    "##### download many files (OBSOLETE, SWITCHING TO MARIADB ON EC2)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "444a9040",
   "metadata": {},
   "source": [
    "process_start_time = datetime.datetime.now()\n",
    "hours_in_year = 365*24\n",
    "count = 0\n",
    "for url, outpath in zip(urls, outpaths):\n",
    "    file_start_time = datetime.datetime.now()\n",
    "    temp_fpath = download_file(url, dirpath=temp_dirpath)\n",
    "    subset_pageviews_by_page_titles(temp_fpath,outpath,all_titles)\n",
    "    file_end_time = datetime.datetime.now()\n",
    "    clear_output(wait=True)\n",
    "    count += 1\n",
    "    print(outpath)\n",
    "    print(f'process time so far: {file_end_time - start_time}')\n",
    "    frac_done = max(count / hours_in_year, .0000001)\n",
    "    print(f'fraction done: {frac_done}')\n",
    "    process_time_so_far = dt.now() - process_start_time\n",
    "    finish_time = process_start_time + process_time_so_far / frac_done\n",
    "    print (f'expected finish time: {finish_time}')\n",
    "    os.remove(temp_fpath) # i forgot this the first time, it screwed me!\n",
    "process_end_time = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88ca4b9",
   "metadata": {},
   "source": [
    "###### function ```subset_pageviews_by_page_titles``` to clean and filter pageview records"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a07d144b",
   "metadata": {},
   "source": [
    "def subset_pageviews_by_page_titles(fpath_in, fpath_out, page_titles, proj='ja'):\n",
    "    os.makedirs(os.path.dirname(fpath_out), exist_ok=True)\n",
    "    with (open_hour_file(fpath_in) as f_in, \n",
    "          open(fpath_out, 'w', encoding='utf-8') as f_out\n",
    "         ):\n",
    "        while (line := f_in.readline()):\n",
    "            if line[:3] != proj + ' ':\n",
    "                continue\n",
    "            lst = line.strip().split(sep=' ')\n",
    "            if lst[1] in page_titles:\n",
    "                f_out.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5d84de",
   "metadata": {},
   "source": [
    "###### function ```subset_pageviews_by_project``` to clean and filter pageview records"
   ]
  },
  {
   "cell_type": "raw",
   "id": "669b2b6f",
   "metadata": {},
   "source": [
    "def subset_pageviews_by_project(fpath_in, fpath_out, proj='ja'):\n",
    "    os.makedirs(os.path.dirname(fpath_out), exist_ok=True)\n",
    "    with (open_hour_file(fpath_in) as f_in, \n",
    "          open(fpath_out, 'w', encoding='utf-8') as f_out\n",
    "         ):\n",
    "        while (line := f_in.readline()):\n",
    "            if line[:3] != proj + ' ':\n",
    "                continue\n",
    "            f_out.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
