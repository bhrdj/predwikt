{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48660241-8117-4a73-b0b4-df969997b4ec",
   "metadata": {},
   "source": [
    "# get pageviews with AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64d3202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mysql_user = 'ubuntu'\n",
    "# mysql_pass = input(f'Enter the MySQL password for user {mysql_user}: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "7c5e4410",
   "metadata": {},
   "outputs": [],
   "source": [
    "todays_date = dt.datetime.now(tz=dt.timezone(dt.timedelta(hours=8))).strftime('%Y-%m-%d')\n",
    "logfilepath = '../data/logs/pageviews-log_' + todays_date + '_' + str(0) + '.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efed6e0",
   "metadata": {},
   "source": [
    "#### how to do jupyter with aws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b3ed43",
   "metadata": {},
   "source": [
    "- https://dataschool.com/data-modeling-101/running-jupyter-notebook-on-an-ec2-server/\n",
    "    - except jupyter_notebook_config.py_ should be ...config.py instead\n",
    "- https://gist.github.com/J535D165/0e840291e7b2598ec157e13e9b9ca569\n",
    "    - trying this for how to use nohup\n",
    "- some medium [article](https://medium.com/@christinakouride/a-beginners-guide-to-running-jupyter-notebook-on-amazon-ec2-69e1b74e73cc#:~:text=Your%20Jupyter%20Notebook%20server%20will,for%20time%20not%20using%20it.)\n",
    "    - they pointed out that notebook will keep running, but didn't mention nohup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "17eba2f0-f33b-40f6-ae44-30c348ca5a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, gzip, pickle, io, logging, inspect, functools\n",
    "import pandas as pd, datetime as dt\n",
    "import mysql.connector as mysql, sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c9239c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.7\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(python_version())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c85e5e9",
   "metadata": {},
   "source": [
    "## setup logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "227efc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('1.22-sfb-get-pageviews-with-AWS')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# create file handler which logs even debug messages\n",
    "fh = logging.FileHandler(logfilepath)\n",
    "fh.setLevel(logging.DEBUG)\n",
    "# create console handler with a higher log level\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.ERROR)\n",
    "# create formatter and add it to the handlers\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fh.setFormatter(formatter)\n",
    "ch.setFormatter(formatter)\n",
    "# add the handlers to the logger\n",
    "logger.addHandler(fh)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "# USAGE:\n",
    "# logger.info('foobarbazquxquuxquuzcorgegraultgarplywaldofredplughxyzzythud')\n",
    "\n",
    "# https://docs.python.org/3/howto/logging-cookbook.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "50f082b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_args(func):\n",
    "    \"\"\"\n",
    "    Decorator to print function call details.\n",
    "    This includes parameters names and effective values.\n",
    "    \"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        func_args = inspect.signature(func).bind(*args, **kwargs).arguments\n",
    "        func_args_str = \", \".join(map(\"{0[0]} = {0[1]!r}\".format, func_args.items()))\n",
    "        logger.info(f\"start {func.__module__}.{func.__qualname__} ( {func_args_str} )\")\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        finally:\n",
    "            logger.info(f\"finish {func.__module__}.{func.__qualname__} ( {func_args_str} )\\n\")\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "56fb7eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_simply(func):\n",
    "    \"\"\"\n",
    "    Decorator to print function call details.\n",
    "    This includes parameters names and effective values.\n",
    "    \"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        func_args = inspect.signature(func).bind(*args, **kwargs).arguments\n",
    "        func_args_str = \", \".join(map(\"{0[0]} = {0[1]!r}\".format, func_args.items()))\n",
    "        logger.info(f\"start {func.__module__}.{func.__qualname__}\")\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        finally:\n",
    "            logger.info(f\"finish {func.__module__}.{func.__qualname__}\\n\")\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0766d3",
   "metadata": {},
   "source": [
    "##### login to mariadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "64eca6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_simply\n",
    "def connect_mariadb(host='localhost', user=mysql_user, passwd=mysql_pass, dbname='jawiki'):\n",
    "    \"\"\"\n",
    "    connect to mariadb and return: \n",
    "        cxn, cur, engine, conn\n",
    "    \"\"\"\n",
    "    cxn = mysql.connect(host=host,user=user,passwd=passwd, database=dbname)\n",
    "    cur = cxn.cursor()\n",
    "\n",
    "    connection_str = 'mysql+mysqlconnector://'+user+':'+passwd+'@'+host+'/'+dbname  # removed this after host +':'+dbport\n",
    "    try:\n",
    "        engine = sqlalchemy.create_engine(connection_str)\n",
    "        conn = engine.connect()\n",
    "    except Exception as e:\n",
    "        print('Database connection error - check creds')\n",
    "        print(e)\n",
    "    return cxn, cur, engine, conn\n",
    "\n",
    "cxn, cur, engine, conn = connect_mariadb()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2abe8c",
   "metadata": {},
   "source": [
    "## get page_titles and urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee994dc",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dac2b62",
   "metadata": {},
   "source": [
    "###### function get_pageviews_urls_and_outpaths_by_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "e2e46101",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_args\n",
    "def get_pageviews_urls_by_year(year:int) -> list[str]:\n",
    "    \"\"\"\n",
    "    Programmatically generate the urls and local file structure to get pageviews hourfiles.\n",
    "    INPUT: year as integer\n",
    "    OUTPUT: list of urls to all the hourfiles for that year\n",
    "    NOTE: filenames are formatted as: \n",
    "        'pageviews-20210101-000000.gz', i.e.\n",
    "        'pageviews-yyyymmdd-hhmmss.gz', although 'mmss' is always '0000'    \n",
    "    \"\"\"\n",
    "    hour_strings = list(map(lambda x: str(x).zfill(2), range(0,24)))  # '00' through '23' \n",
    "    dates = pd.date_range(dt.datetime(year,1,1), \n",
    "                          end=dt.datetime(year+1,1,1), \n",
    "                          freq='D')  # , tz='Japan'                   # each date in the year\n",
    "    base_url = 'https://dumps.wikimedia.org/other/pageviews/'\n",
    "    urls = [f'{base_url}{d.year}/{d.year}-{str(d.month).zfill(2)}'\n",
    "            f'/pageviews-{d.year}{str(d.month).zfill(2)}{str(d.day).zfill(2)}-{h}0000.gz'\n",
    "            for d in dates for h in hour_strings]\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899ddcee-6006-4aa1-9219-877a34704748",
   "metadata": {},
   "source": [
    "##### function download_file to temporarily store hourfiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "c1d5b0f9-df90-4710-8349-543a9723c17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_args\n",
    "def download_file(url, dirpath='./'):\n",
    "    \"\"\"\n",
    "    Carefully downloads the file from the url to the local directory dirpath.\n",
    "    Should work for large files, and hopefully for poor connections, etc.\n",
    "    \"\"\"\n",
    "    local_filepath = dirpath + url.split('/')[-1]\n",
    "    # NOTE the stream=True parameter below\n",
    "    with requests.get(url, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(local_filepath, 'wb') as f:\n",
    "            for chunk in r.iter_content(chunk_size=131072):   #8192\n",
    "                # If you have chunk encoded response uncomment if\n",
    "                # and set chunk_size parameter to None.\n",
    "                #if chunk: \n",
    "                f.write(chunk)\n",
    "    return local_filepath\n",
    "# https://stackoverflow.com/questions/16694907/download-large-file-in-python-with-requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb7911b",
   "metadata": {},
   "source": [
    "###### function get_pageviews_subset_by_project to get all jawiki pageviews from an hourfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "d87fc541",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_args\n",
    "def open_hour_file(path:str):\n",
    "    \"\"\"\n",
    "    INPUT: path to a .gz file \n",
    "    OUTPUT: open file handle\n",
    "    USAGE:\n",
    "        with open_hour_file(foo) as bar:\n",
    "            baz\n",
    "    BEHAVIOR: if filename doesn't have .gz extension, tries to open without decompression\n",
    "    \n",
    "    \"\"\"\n",
    "    if path[-3:] == \".gz\":\n",
    "        return gzip.open(path, mode=\"rt\", encoding=\"utf-8\", errors=\"replace\")\n",
    "    else:\n",
    "        return open(path, mode=\"rt\", encoding=\"utf-8\", errors=\"replace\")\n",
    "# https://github.com/mediawiki-utilities/python-mwviews/blob/main/src/mwviews/utilities/aggregate.py\n",
    "# https://stackoverflow.com/questions/30582162/creating-a-missing-directory-file-structure-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "41d55e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_args\n",
    "def parse_utc_time_from_filename(filename:str) -> dt.datetime:\n",
    "    \"\"\"\n",
    "    filenames are formatted as: \n",
    "        'pageviews-20210101-000000.gz', i.e.\n",
    "        'pageviews-yyyymmdd-hhmmss.gz', although 'mmss' is always '0000'    \n",
    "    \"\"\"\n",
    "    [d, t] = filename.split('-')[1:]  # split filename into yyyymmdd and hhmmss\n",
    "    return dt.datetime(int(d[:4]), int(d[4:6]), int(d[6:]), int(t[:2]), tzinfo=dt.timezone.utc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "4ab4ea3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_args\n",
    "def get_pageviews_subset_by_project(fpath_in, proj:str='ja') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    INPUT:\n",
    "        fpath: local filepath to pageviews records as text file\n",
    "        proj: mediawiki project code\n",
    "    OUTPUT:\n",
    "        dataframe ready for database ingestion\n",
    "    \"\"\"\n",
    "    lst = []\n",
    "    colnames=['domain_code','page_title','count_views','total_response_size']\n",
    "    # subset pageview records by project as list of strings\n",
    "    with open_hour_file(fpath_in) as f_in:\n",
    "        while (line := f_in.readline()):\n",
    "            if line[:3] != proj + ' ':\n",
    "                continue\n",
    "            lst.append(line)\n",
    "    # turn list of strings into dataframe\n",
    "    df = pd.read_csv(\n",
    "        io.StringIO('\\n'.join(lst))\n",
    "        ,delim_whitespace=True\n",
    "        ,names=colnames)\n",
    "    # add datetime_viewed_UTC as column based on filename\n",
    "    parsed_datetime = parse_utc_time_from_filename(fpath_in.split(sep='/')[-1])\n",
    "    df = df.assign(datetime_viewed_UTC=parsed_datetime)\n",
    "    # add datetime_added_UTC as the time when this function runs\n",
    "    now_datetime = dt.datetime.now(tz=dt.timezone.utc)\n",
    "    df = df.assign(datetime_added_UTC=now_datetime)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9797a7d",
   "metadata": {},
   "source": [
    "###### function etl_pageviews_by_years_and_projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "3520a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_args\n",
    "def does_table_exist(tablename:str, dbname:str='jawiki', con=conn) -> bool:\n",
    "    \"\"\"\n",
    "    run SQL query to look for tablename, return boolean\n",
    "    \"\"\"\n",
    "    sql = f\"\"\"\n",
    "    SELECT * \n",
    "        FROM information_schema.tables\n",
    "    WHERE table_schema = '{dbname}' \n",
    "        AND table_name = '{tablename}'\n",
    "    LIMIT 1;\n",
    "    \"\"\"\n",
    "    return bool(pd.read_sql(sql, con).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "6fb46f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_args\n",
    "def create_pageviews_table(con=conn):\n",
    "    \"\"\"\n",
    "    run SQL code to create pageviews table\n",
    "    \"\"\"\n",
    "    \n",
    "    sql = \"\"\"\n",
    "    CREATE TABLE pageviews (\n",
    "        row_id BIGINT(20) AUTO_INCREMENT PRIMARY KEY\n",
    "        ,domain_code TEXT\n",
    "        ,page_title TEXT\n",
    "        ,count_views BIGINT(20)\n",
    "        ,total_response_size BIGINT(20)\n",
    "        ,datetime_viewed_UTC TIMESTAMP DEFAULT 0\n",
    "        ,datetime_added_UTC TIMESTAMP DEFAULT CURRENT_TIMESTAMP \n",
    "    )\n",
    "    ;\n",
    "    \"\"\"\n",
    "    conn.execute(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267b6cd6",
   "metadata": {},
   "source": [
    "###### calculate finish time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "5e878e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_forecast_of_completion(count, process_start_time, years):\n",
    "    hours_in_year = 365.25*24\n",
    "    num_years = len(years)\n",
    "    frac_done = count / hours_in_year / num_years\n",
    "    time_now = dt.datetime.now()\n",
    "    process_time_so_far = time_now - process_start_time\n",
    "    finish_time = process_start_time + (process_time_so_far / frac_done)\n",
    "    logger.info(\n",
    "        f'-----------\\n'\n",
    "        f'PROCESS TIME SO FAR:  {time_now - process_start_time}\\n'\n",
    "        f'FRACTION DONE:        {frac_done}\\n'\n",
    "        f'EXPECTED FINISH TIME: {finish_time}\\n'\n",
    "        '-----------\\n'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2f5c64",
   "metadata": {},
   "source": [
    "## main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "82b017a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_args\n",
    "def etl_pageviews_by_years_and_projects(years:list[int], project:str='ja', logfilepath:str=logfilepath, con=conn):\n",
    "    if not does_table_exist('pageviews'):\n",
    "        create_pageviews_table(con)\n",
    "    process_start_time = dt.datetime.now()\n",
    "    for year in years:\n",
    "        urls = get_pageviews_urls_by_year(year)\n",
    "        urls = urls[:3]   ############################## TRUNCATED FOR DEBUGGING\n",
    "        for url in urls:\n",
    "            # start counts\n",
    "            file_count = 0\n",
    "            \n",
    "            # actual work\n",
    "            temp_fpath = download_file(url, dirpath='../data/temp/')\n",
    "            pageviews = get_pageviews_subset_by_project(temp_fpath)\n",
    "            pageviews.to_sql(name='pageviews',con=con, if_exists='append', index=False)\n",
    "            \n",
    "            # complete counts\n",
    "            file_count += 1\n",
    "            # log and cleanup\n",
    "            log_forecast_of_completion(file_count, process_start_time, years)\n",
    "            os.remove(temp_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "7893638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "etl_pageviews_by_years_and_projects([2016])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1268006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7580b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "e48126ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count(*)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>583783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count(*)\n",
       "0    583783"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql('select count(*) from pageviews;', con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "b5f0b2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Field</th>\n",
       "      <th>Type</th>\n",
       "      <th>Null</th>\n",
       "      <th>Key</th>\n",
       "      <th>Default</th>\n",
       "      <th>Extra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>row_id</td>\n",
       "      <td>bigint(20)</td>\n",
       "      <td>NO</td>\n",
       "      <td>PRI</td>\n",
       "      <td>None</td>\n",
       "      <td>auto_increment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>domain_code</td>\n",
       "      <td>text</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>page_title</td>\n",
       "      <td>text</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>count_views</td>\n",
       "      <td>bigint(20)</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>total_response_size</td>\n",
       "      <td>bigint(20)</td>\n",
       "      <td>YES</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>datetime_viewed_UTC</td>\n",
       "      <td>timestamp</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "      <td>0000-00-00 00:00:00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>datetime_added_UTC</td>\n",
       "      <td>timestamp</td>\n",
       "      <td>NO</td>\n",
       "      <td></td>\n",
       "      <td>current_timestamp()</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Field        Type Null  Key              Default  \\\n",
       "0               row_id  bigint(20)   NO  PRI                 None   \n",
       "1          domain_code        text  YES                      None   \n",
       "2           page_title        text  YES                      None   \n",
       "3          count_views  bigint(20)  YES                      None   \n",
       "4  total_response_size  bigint(20)  YES                      None   \n",
       "5  datetime_viewed_UTC   timestamp   NO       0000-00-00 00:00:00   \n",
       "6   datetime_added_UTC   timestamp   NO       current_timestamp()   \n",
       "\n",
       "            Extra  \n",
       "0  auto_increment  \n",
       "1                  \n",
       "2                  \n",
       "3                  \n",
       "4                  \n",
       "5                  \n",
       "6                  "
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql('desc pageviews;', con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "5dbf1915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain_code</th>\n",
       "      <th>page_title</th>\n",
       "      <th>count_views</th>\n",
       "      <th>total_response_size</th>\n",
       "      <th>datetime_viewed_UTC</th>\n",
       "      <th>datetime_added_UTC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>458752</th>\n",
       "      <td>ja</td>\n",
       "      <td>„ÇÑ„Åæ„Å™„Åø„Éà„É≥„Éç„É´</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>2022-03-20 12:02:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524288</th>\n",
       "      <td>ja</td>\n",
       "      <td>Âú∞„ÅÆÂ°©„ÄÅ‰∏ñ„ÅÆÂÖâ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>2022-03-20 12:02:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459008</th>\n",
       "      <td>ja</td>\n",
       "      <td>„Çé</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>2022-03-20 12:02:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524544</th>\n",
       "      <td>ja</td>\n",
       "      <td>ÂùÇ‰∫ï‰∏âÈÉé</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>2022-03-20 12:02:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459264</th>\n",
       "      <td>ja</td>\n",
       "      <td>„Ç¢„Ç§„É™„Çπ„Ç™„Éº„É§„Éû</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>2022-03-20 12:02:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       domain_code page_title  count_views  total_response_size  \\\n",
       "row_id                                                            \n",
       "458752          ja   „ÇÑ„Åæ„Å™„Åø„Éà„É≥„Éç„É´            1                    0   \n",
       "524288          ja    Âú∞„ÅÆÂ°©„ÄÅ‰∏ñ„ÅÆÂÖâ            1                    0   \n",
       "459008          ja          „Çé            1                    0   \n",
       "524544          ja       ÂùÇ‰∫ï‰∏âÈÉé            3                    0   \n",
       "459264          ja   „Ç¢„Ç§„É™„Çπ„Ç™„Éº„É§„Éû            3                    0   \n",
       "\n",
       "       datetime_viewed_UTC  datetime_added_UTC  \n",
       "row_id                                          \n",
       "458752 2016-01-01 02:00:00 2022-03-20 12:02:33  \n",
       "524288 2016-01-01 02:00:00 2022-03-20 12:02:33  \n",
       "459008 2016-01-01 02:00:00 2022-03-20 12:02:33  \n",
       "524544 2016-01-01 02:00:00 2022-03-20 12:02:33  \n",
       "459264 2016-01-01 02:00:00 2022-03-20 12:02:33  "
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql('select * from pageviews order by datetime_viewed_UTC desc limit 5;', con=conn, index_col='row_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "49a51e96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "1476414f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nohup jupyter notebook &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "ebd1e8c6-edfe-4e9d-94b5-47806c072bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jupyter nbconvert --to script '1.22-sfb-get-pageviews-with-AWS-lambda.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162ca680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cc42ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cdac068",
   "metadata": {},
   "source": [
    "##### test running cell while laptop sleeping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4629d60",
   "metadata": {},
   "source": [
    "###### idea"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018ec808",
   "metadata": {},
   "source": [
    "- consider the case where:\n",
    "    - i start the following cell's script as follows:\n",
    "        - on AWS from a ssh terminal \n",
    "        - via nohup jupyter on computer A\n",
    "    - then i disconnect the ssh from computer A\n",
    "        - so that the cell is still running in the instance\n",
    "- then i find the result that:\n",
    "    - i can reopen jupyter from another ssh terminal\n",
    "    - i can interrupt the script\n",
    "    - but i can't see its in-process results\n",
    "- strategy for now:\n",
    "    - develop the script on whatever computers\n",
    "    - then run it from a browser tab in my android phone\n",
    "        - that way i can keep \"tabs\" on it (üòâ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8511d2b",
   "metadata": {},
   "source": [
    "###### function ```subset_pageviews_by_page_titles``` to clean and filter pageview records"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b02996a2",
   "metadata": {},
   "source": [
    "def subset_pageviews_by_page_titles(fpath_in, fpath_out, page_titles, proj='ja'):\n",
    "    os.makedirs(os.path.dirname(fpath_out), exist_ok=True)\n",
    "    with (open_hour_file(fpath_in) as f_in, \n",
    "          open(fpath_out, 'w', encoding='utf-8') as f_out\n",
    "         ):\n",
    "        while (line := f_in.readline()):\n",
    "            if line[:3] != proj + ' ':\n",
    "                continue\n",
    "            lst = line.strip().split(sep=' ')\n",
    "            if lst[1] in page_titles:\n",
    "                f_out.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17aea8f",
   "metadata": {},
   "source": [
    "###### function ```subset_pageviews_by_project``` to clean and filter pageview records"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0487eb52",
   "metadata": {},
   "source": [
    "def subset_pageviews_by_project(fpath_in, fpath_out, proj='ja'):\n",
    "    os.makedirs(os.path.dirname(fpath_out), exist_ok=True)\n",
    "    with (open_hour_file(fpath_in) as f_in, \n",
    "          open(fpath_out, 'w', encoding='utf-8') as f_out\n",
    "         ):\n",
    "        while (line := f_in.readline()):\n",
    "            if line[:3] != proj + ' ':\n",
    "                continue\n",
    "            f_out.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851405a6",
   "metadata": {},
   "source": [
    "###### unpickle page list"
   ]
  },
  {
   "cell_type": "raw",
   "id": "80ea1cf6",
   "metadata": {},
   "source": [
    "def failed_decode(a):\n",
    "    try:\n",
    "        a.decode('utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def bytearray_to_str(a:bytearray, encoding='utf-8') -> str:\n",
    "    if type(a) != bytearray:\n",
    "        return a        \n",
    "    while failed_decode(a):\n",
    "        a = a[:-1]\n",
    "    return str(a.decode(encoding))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fa10a86e",
   "metadata": {},
   "source": [
    "with open('../data/processed/jawiki/' + 'disaster_descendants_raw.pickle', 'rb') as f:\n",
    "    disaster_descendants_raw = pickle.load(f)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4623a63e",
   "metadata": {},
   "source": [
    "disaster_cat_page_ids = {'ÁÅ´Â±±ÁÅΩÂÆ≥':2390743, 'ÁÜ±Â∏Ø‰ΩéÊ∞óÂúß':626482, 'Èõ™ÂÆ≥':2390774, 'Âú∞Èúá':135264, 'Ê¥•Ê≥¢':765772}  # 'Ëá™ÁÑ∂ÁÅΩÂÆ≥':137069, \n",
    "disasters_english = {'ÁÅ´Â±±ÁÅΩÂÆ≥':'VolcanicDisaster', 'ÁÜ±Â∏Ø‰ΩéÊ∞óÂúß':'TropicalCyclones', 'Èõ™ÂÆ≥':'SnowDamage', 'Âú∞Èúá':'Earthquake', 'Ê¥•Ê≥¢':'Tsunami'}\n",
    "disasters = list(disaster_cat_page_ids.keys())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b525a459",
   "metadata": {},
   "source": [
    "d = {}\n",
    "for i in disaster_descendants_raw:\n",
    "    d[i] = (disaster_descendants_raw[i]\n",
    "            .drop_duplicates(subset='id')\n",
    "            .applymap(bytearray_to_str)\n",
    "           )\n",
    "    d[i] = d[i][d[i].namespace == 0]\n",
    "    d[i]['page_title'] = d[i].name.map(lambda x: str(x).split(sep='\\n')[-1])\n",
    "disaster_descendants = d\n",
    "del d"
   ]
  },
  {
   "cell_type": "raw",
   "id": "48a02698",
   "metadata": {},
   "source": [
    "all_titles = [j for i in disaster_descendants for j in disaster_descendants[i].page_title]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fc6f08",
   "metadata": {},
   "source": [
    "###### FOUND OUT THAT THERE'RE SOME UNRELATED COLUMNS IN THE CATEGORIES:\n",
    "NEED TO CLEAN THE CATEGORIES"
   ]
  },
  {
   "cell_type": "raw",
   "id": "56fe26e8",
   "metadata": {},
   "source": [
    "for i in disaster_descendants:\n",
    "    print(i)\n",
    "    print(disaster_descendants[i][disaster_descendants[i].page_title.isin(['WHITEBERRY'])])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e69afc72",
   "metadata": {},
   "source": [
    "disaster_descendants['ÁÅ´Â±±ÁÅΩÂÆ≥'][disaster_descendants['ÁÅ´Â±±ÁÅΩÂÆ≥'].page_title.isin(['WHITEBERRY'])]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0484c514",
   "metadata": {},
   "source": [
    "all_titles[5444:5470]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9004c895",
   "metadata": {},
   "source": [
    "[i for i in all_titles if i == 'WHITEBERRY']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
