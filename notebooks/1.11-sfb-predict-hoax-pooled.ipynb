{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf9a66eb-eafa-495f-bf29-01a066f97e1c",
   "metadata": {},
   "source": [
    "# predict hoax - pooled (SHOULDN'T POOL PAIRED DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa41e1ba-5991-488c-bd45-eb5589bd79d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## get data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b83a42-a357-425a-b420-24206451f44c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc5a7b63-3fd9-4511-a23b-d577bc40579e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, patsy\n",
    "import pandas as pd, numpy as np\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "path = '/home/bhrdwj/git/predwikt/data/raw/wiki_reliability/unzipped/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f2d5ca6-ac51-4f63-a3a0-e90f55121ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dif = pd.read_csv(path+'hoax_difftxt.csv', usecols=lambda x: x not in ['Unnamed: 0'])\n",
    "ful = pd.read_csv(path+'hoax_fulltxt.csv', usecols=lambda x: x not in ['Unnamed: 0'])\n",
    "fea = pd.read_csv(path+'hoax_features.csv', usecols=lambda x: x not in ['Unnamed: 0'])\n",
    "\n",
    "fea = fea.set_index('revision_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9b9e1f6-9386-4466-8d6e-e592a0d37063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1385, 1386, 2788)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dif.shape[0], ful.shape[0], fea.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70372454-618c-48ea-b0d6-affe4c51568f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### denormalize for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7349ef-b365-46df-b20f-a47781140306",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Create denormalized dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d92517e-f8e4-46e6-985c-b7c59146e1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate positive and negative observations, assign dummy vars, rename columns for concatenation\n",
    "ful_pos = ful[['revision_id_pos', 'txt_pos', 'page_id']].set_index('revision_id_pos').assign(hoax=1).rename(columns={'txt_pos':'ful'})\n",
    "ful_neg = ful[['revision_id_neg', 'txt_neg', 'page_id']].set_index('revision_id_neg').assign(hoax=0).rename(columns={'txt_neg':'ful'})\n",
    "dif_pos = dif[['revision_id_pos', 'difftxt_pos', 'page_id']].set_index('revision_id_pos').assign(hoax=1).rename(columns={'difftxt_pos':'dif'})\n",
    "dif_neg = dif[['revision_id_neg', 'difftxt_neg', 'page_id']].set_index('revision_id_neg').assign(hoax=0).rename(columns={'difftxt_neg':'dif'})\n",
    "\n",
    "# Concatenate positive and negative observations to taller form\n",
    "fea = fea.astype({'page_id':str}).rename(columns={'has_template':'hoax'})\n",
    "ful = pd.concat((ful_pos, ful_neg)).astype({'page_id':str})\n",
    "dif = pd.concat((dif_pos, dif_neg)).astype({'page_id':str})\n",
    "\n",
    "# Join the text data onto the features data\n",
    "df = fea.join(ful, rsuffix='_ful').join(dif, rsuffix='_dif', lsuffix='_fea')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b390d6-1afc-4dbb-81e1-2b39a0b1d45f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Remove redundant page_id columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dee8913f-e4da-4317-8808-df10b0f17f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 rows where page_id doesn't match\n",
      "\n",
      "page_id_fea     0\n",
      "page_id_ful    16\n",
      "page_id_dif    18\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Confirm that page_id is always a match whenever it isn't NaN, for fully non-null rows\n",
    "(df[df.columns[df.columns.str.startswith('page_id')]]\n",
    "    .loc[~df.isna().any(axis=1)]\n",
    "    .loc[(df.page_id_fea != df.page_id_ful) | (df.page_id_ful != df.page_id_dif)]\n",
    "    .pipe(lambda x: print(f\"There are {x.shape[0]} rows where page_id doesn't match\\n\")))\n",
    "\n",
    "# Check which page_id columns have how-many nulls\n",
    "df[df.columns[df.columns.str.startswith('page_id')]].isna().sum().pipe(print)\n",
    "\n",
    "# Drop the redundant page_id columns\n",
    "df = df[df.columns.difference(['page_id_ful', 'page_id_dif'])].rename(columns={'page_id_fea':'page_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dd9bdd-1101-46fd-972a-fe538d8caa82",
   "metadata": {},
   "source": [
    "#### Remove redundate hoax columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cfb3e87-16c1-42c8-87ab-989940f49fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 rows where hoax doesn't match\n",
      "\n",
      "hoax_dif    18\n",
      "hoax_fea     0\n",
      "hoax_ful    16\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Confirm that hoax is similarly a match\n",
    "(df[df.columns[df.columns.str.startswith('hoax')]]\n",
    "    .loc[~df.isna().any(axis=1)] \n",
    "    .loc[(df.hoax_fea != df.hoax_dif)] \n",
    "    .pipe(lambda x: print(f\"There are {x.shape[0]} rows where hoax doesn't match\\n\")))\n",
    "\n",
    "# Check which hoax columns have how-many nulls\n",
    "df[df.columns[df.columns.str.startswith('hoax')]].isna().sum().pipe(print)\n",
    "\n",
    "# Drop the redundant hoax columns\n",
    "df = df[df.columns.difference(['hoax_dif', 'hoax_ful'])].rename(columns={'hoax_fea':'hoax'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a90351d-650c-46a2-9114-d51f139401ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Confirm that no observations were lost, and clean namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d38645e-c9a5-4fd3-949f-d696b7648dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2788, 25)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaabf2c4-f6fe-4bd3-9f29-bb6fcdb506bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del fea, ful, dif, ful_pos, ful_neg, dif_pos, dif_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0aaec34-276e-40a8-a03d-7ba9d0da52d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### data dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ce61287-18ba-4373-a813-26556076098e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Page ID of the revision', 'ID of the revision',\n",
       "       'ID of the corresponding pos/neg revision',\n",
       "       'Change in bytes of revision text',\n",
       "       'Average length of stemmed text', 'Count of images in tags',\n",
       "       'Count of infobox templates',\n",
       "       'Total length of paragraphs without references',\n",
       "       'Number of shortened footnotes (i.e., citations with page numbers linking to the full citation for a source)',\n",
       "       \"Count of matches from Wikipedia's words to watch: words that are flattering, vague or endorsing a viewpoint\",\n",
       "       'Count of words for the revision',\n",
       "       'Number of characters in the full article',\n",
       "       'Number of characters in the content section of an article',\n",
       "       'Count of external links not in Wikipedia',\n",
       "       'Count of level-2 headings',\n",
       "       'Count of reference tags, indicating the presence of a citation',\n",
       "       'Count of links to pages on Wikipedia',\n",
       "       'Letter grade of article quality prediction',\n",
       "       'Count of templates that come up on a citation link',\n",
       "       'Count of citation needed templates',\n",
       "       'Number of who templates, signaling vague \"authorities\", i.e., \"historians say\", \"some researchers\"',\n",
       "       'Total count of all transcluded templates',\n",
       "       'Count of categories an article has',\n",
       "       'Binary label indicating presence or absence of a reliability template in our dataset'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtdt = pd.read_csv('../data/raw/schemas/schema_wiki-reliability.tsv', sep='\\t').set_index('Field').squeeze()\n",
    "mtdt.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31b13d2-6b06-42ef-9543-43b64be6ac2a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Predict pooled without text (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dc0d67-9521-4e65-9355-63bdbd3c0290",
   "metadata": {
    "tags": []
   },
   "source": [
    "### data prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d73a6a9b-5aef-4d95-b0d3-763fd033c5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[df.columns.difference(['dif','ful', 'revision_id.key', 'revision_text_bytes'])]\n",
    "Xcols1 = df1.columns.difference(['hoax', 'headings_by_level(2)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06fd5c46-9f6c-47aa-ba01-faa35ce10857",
   "metadata": {},
   "outputs": [],
   "source": [
    "y,X = patsy.dmatrices('hoax ~ '+' + '.join(Xcols1), data=df1, return_type='dataframe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00359a27-c98b-48de-bd1e-0c02833c55e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr, Xte, ytr, yte = train_test_split(X,y, test_size=.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0fde756-d431-4041-b924-cf0e905c1a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = StandardScaler()\n",
    "# def scale_reindex(df):\n",
    "#     matrix = scaler.fit_transform(df)\n",
    "#     return pd.DataFrame(data=matrix, index=df.index, columns=df.columns)\n",
    "\n",
    "# [Xtr,Xte] = map(scale_reindex, [Xtr,Xte])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422c053e-8e25-4c9a-a4e6-760bc01dea5b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1305985a-a9a8-48bc-969d-342e742dc6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d827d6f-7d02-4a1e-a883-007d635f4718",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhrdwj/anaconda3/envs/py39/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:112: UserWarning: Features [  0 127] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "/home/bhrdwj/anaconda3/envs/py39/lib/python3.9/site-packages/sklearn/feature_selection/_univariate_selection.py:113: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "skb1 = SelectKBest(k=20)\n",
    "skb1.fit(X,np.ravel(y))\n",
    "feats1 = X.columns[skb1.get_support()]\n",
    "feats1 = [i for i in feats1.tolist() if not i.find('page_id') > -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35b32aba-a2e6-4e94-bea6-9082cfb0731a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['article_quality_score[T.C]',\n",
       " 'cite_templates',\n",
       " 'cn_templates',\n",
       " 'external_links',\n",
       " 'paragraphs_without_refs',\n",
       " 'revision_chars',\n",
       " 'revision_content_chars',\n",
       " 'revision_templates',\n",
       " 'revision_wikilinks',\n",
       " 'revision_words',\n",
       " 'stems_length',\n",
       " 'words_to_watch_matches']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feats1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8358a1-7b59-42a9-b857-aafb61f91702",
   "metadata": {
    "tags": []
   },
   "source": [
    "### initialize and fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68ff252d-dda1-4146-80f7-30a41bfc6503",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bhrdwj/anaconda3/envs/py39/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bhrdwj/anaconda3/envs/py39/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bhrdwj/anaconda3/envs/py39/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/bhrdwj/anaconda3/envs/py39/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=array([0.0001    , 0.00031623, 0.001     ]),\n",
       "                     random_state=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logcv = LogisticRegressionCV(Cs=np.logspace(-4, -3, num=3), random_state=0)\n",
    "logcv.fit(Xtr[feats1], np.ravel(ytr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50b40df-4904-4bf5-afd7-43a4adf74479",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### check results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c2bf84a-7346-46ce-9529-84be40423df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.001])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logcv.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f53b4dc5-4de3-4db7-9fc8-1d2ff2bfa7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6140035906642729"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logcv.score(Xte[feats1], yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e629f9c-3c11-4394-b481-73f8210e28ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hoax    0.517056\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yte.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affa56a9-b979-440a-9268-2289f697af4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### review fitted coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4b392923-ea49-4f4c-9f39-b050058040ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs = pd.Series(logcv.coef_.flatten(), index=feats1).squeeze().sort_values(ascending=False, key=abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d92d068-6190-42f5-b55e-715190741676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "external_links               -0.011305\n",
       "revision_templates            0.008766\n",
       "words_to_watch_matches        0.005868\n",
       "cn_templates                  0.001983\n",
       "revision_words               -0.000922\n",
       "cite_templates                0.000773\n",
       "article_quality_score[T.C]    0.000627\n",
       "revision_wikilinks            0.000340\n",
       "revision_content_chars        0.000112\n",
       "stems_length                  0.000092\n",
       "revision_chars               -0.000030\n",
       "paragraphs_without_refs       0.000013\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeffs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
