{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48660241-8117-4a73-b0b4-df969997b4ec",
   "metadata": {},
   "source": [
    "# insert disaster pageviews into mariadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d99b2b5",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## password, imports, mariadb_login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3755d68",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19abd44c",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the MySQL password for user ubuntu: mariadb394\n"
     ]
    }
   ],
   "source": [
    "mysql_user = 'ubuntu'\n",
    "mysql_pass = input(f'Enter the MySQL password for user {mysql_user}: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcd000e",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "17eba2f0-f33b-40f6-ae44-30c348ca5a6c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os, requests, gzip, pickle, io, logging, inspect, functools, string, re\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd, datetime as dt\n",
    "import mysql.connector as mysql, sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4293d3",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### login to mariadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0bfb36a0",
   "metadata": {
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def connect_mariadb(host='localhost', user=mysql_user, passwd=mysql_pass, dbname='jawiki'):\n",
    "    \"\"\"\n",
    "    connect to mariadb and return: \n",
    "        cxn, cur, engine, conn\n",
    "    \"\"\"\n",
    "    cxn = mysql.connect(host=host,user=user,passwd=passwd, database=dbname)\n",
    "    cur = cxn.cursor()\n",
    "\n",
    "    connection_str = 'mysql+mysqlconnector://'+user+':'+passwd+'@'+host+'/'+dbname  # removed this after host +':'+dbport\n",
    "    try:\n",
    "        engine = sqlalchemy.create_engine(connection_str)\n",
    "        conn = engine.connect()\n",
    "    except Exception as e:\n",
    "        print('Database connection error - check creds')\n",
    "        print(e)\n",
    "    return cxn, cur, engine, conn\n",
    "\n",
    "cxn, cur, engine, conn = connect_mariadb()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2abe8c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## get page_titles and page_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76935b99",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### unpickle list of disaster pageids (diz_pageids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31253407",
   "metadata": {
    "code_folding": [
     0,
     7
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def failed_decode(a):\n",
    "    try:\n",
    "        a.decode('utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def bytearray_to_str(a:bytearray, encoding='utf-8') -> str:\n",
    "    if type(a) != bytearray:\n",
    "        return a        \n",
    "    while failed_decode(a):\n",
    "        a = a[:-1]\n",
    "    return str(a.decode(encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da558220",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('../data/processed/jawiki/' + 'disaster_descendants_raw.pickle', 'rb') as f:\n",
    "    disaster_descendants_raw = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2cfc7fc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "disaster_cat_page_ids = {'火山災害':2390743, '熱帯低気圧':626482, '雪害':2390774, '地震':135264, '津波':765772}  # '自然災害':137069, \n",
    "disasters_english = {'火山災害':'VolcanicDisaster', '熱帯低気圧':'TropicalCyclones', '雪害':'SnowDamage', '地震':'Earthquake', '津波':'Tsunami'}\n",
    "disasters = list(disaster_cat_page_ids.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4821135",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i in disaster_descendants_raw:\n",
    "    d[i] = (disaster_descendants_raw[i]\n",
    "            .drop_duplicates(subset='id')\n",
    "            .applymap(bytearray_to_str)\n",
    "           )\n",
    "    d[i] = d[i][d[i].namespace == 0]\n",
    "    d[i]['page_title'] = d[i].name.map(lambda x: str(x).split(sep='\\n')[-1])\n",
    "disaster_descendants = d\n",
    "del d, disaster_descendants_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "049f6e07",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'type', 'namespace', 'page_title'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster_descendants['火山災害'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5acb587",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "diz_pageids = [j for i in disaster_descendants for j in disaster_descendants[i].id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee994dc",
   "metadata": {},
   "source": [
    "## function trees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c884ffb",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### get_pageviews_by_pageids_and_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9d9fa08",
   "metadata": {
    "code_folding": [
     3
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_pageviews_by_pageids_and_years(\n",
    "        pids_of_interest:list[int], years:[int]\n",
    "        ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "        INPUTS: \n",
    "        pid_of_interest: pageid to return\n",
    "        years: list of years to include\n",
    "        OUTPUTS: \n",
    "        pd.DataFrame where:\n",
    "            index: utc_date in yyyymmdd\n",
    "            columns: 'mobile', 'desktop', 'app'\n",
    "            values: encoded hourly counts (see note below)\n",
    "            name: pageid\n",
    "        NOTE:\n",
    "        hourly counts are encoded with letters as hours, and numbers as counts\n",
    "        for example, 'C2' means 2 pageviews between 02:00 and 02:59\n",
    "    \"\"\"\n",
    "    paths = []\n",
    "    for year in years:\n",
    "        paths = paths + get_all_paths_in_year(year)\n",
    "    pageid_filter = make_pageid_filter(pids_of_interest)\n",
    "    diz_views = {}\n",
    "    for path in paths[:100]:\n",
    "        diz_views, yyyymmdd = get_hour_counts_for_pid_matches(path, diz_views, pageid_filter)\n",
    "        clear_output(wait=True)\n",
    "        print(f\"started {min(years)},\\ncompleted {yyyymmdd},\\ncontinuing until end of {max(years)}\")\n",
    "    return pd.DataFrame(diz_views).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b162050a",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### get_all_paths_in_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c38e6fd2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_all_paths_in_year(year:int) -> list[str]:\n",
    "    gen = os.walk(f'../data/temp/jawiki_pageviews/{year}/')\n",
    "    filepaths = []\n",
    "    for tup in gen:\n",
    "        for f in tup[2]:\n",
    "            filepaths.append(tup[0]+'/'+f)\n",
    "    filepaths.sort()\n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96694b77",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### make_pageid_filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "623aabf0",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_pageid_filter(pid_allowlist:list[int], con=conn) -> dict:\n",
    "    \"\"\"\n",
    "    INPUTS:\n",
    "        pid_allowlist: list of allowed page_id's\n",
    "        con: SQLAlchemy connection\n",
    "    OUTPUT: dict\n",
    "        keys: all pageids in jawiki  \n",
    "        values: disaster 1, not-disaster 0\n",
    "    \"\"\"\n",
    "    ct = 0\n",
    "    sql = \"select distinct page_id from page;\"\n",
    "    all_pageids = pd.read_sql(sql, conn).squeeze().to_list()\n",
    "    d = {i:0 for i in all_pageids}\n",
    "    for i in pid_allowlist:\n",
    "        d[i] = 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63421557",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### get_hour_counts_for_pid_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bf13039",
   "metadata": {
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_hour_counts_for_pid_matches(path:str, diz_views:dict, pageid_filter:dict=pageid_filter) -> tuple[dict, str]:\n",
    "    \"\"\"\n",
    "        INPUTS:\n",
    "            path: bz2 pageviews_complete daily-file filepath\n",
    "            diz_views: accumulated filtered pageviews data\n",
    "            pageid_filter: dict mapping all jawiki pageids to 1's if \"disaster\" page, 0 otherwise\n",
    "        OUTPUTS:\n",
    "            diz_views: updated filtered pageviews data\n",
    "            yyyymmdd: date as string-num\n",
    "    \"\"\"\n",
    "    yyyymmdd = path.split('/')[-1].split('-')[1]\n",
    "    with open(path) as f:\n",
    "        try: # check if a dict has been assigned for this date yet\n",
    "            diz_views[yyyymmdd]\n",
    "        except KeyError: # make one if it isn't there yet\n",
    "            diz_views[yyyymmdd] = {}\n",
    "        \n",
    "        while (line := f.readline()):\n",
    "            line_split = line.split()\n",
    "            \n",
    "            if len(line_split) < 6: # discard abnormal records missing fields \n",
    "                continue\n",
    "            \n",
    "            pid_str = line_split[2]\n",
    "            try: # redundant check, ignoring pageviews of redirects etc that don't have page_id\n",
    "                pid = int(pid_str)\n",
    "            except ValueError:\n",
    "                continue \n",
    "            \n",
    "            try: # check if page_id is in the list\n",
    "                (ps:=pageid_filter[pid])\n",
    "            except KeyError:\n",
    "                continue\n",
    "            \n",
    "            if ps==1:\n",
    "                access_method = line_split[3]\n",
    "                hour_counts = line_split[5]\n",
    "                diz_views[yyyymmdd][pid_str+'_'+access_method] = hour_counts\n",
    "    return (diz_views, yyyymmdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdbfaff",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "##### ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46d6bec",
   "metadata": {},
   "source": [
    "#### insert_pageviews_into_mariadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01dd84c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_pageviews_into_mariadb(\n",
    "    years:list[int], pagetitles:list[str], project:str='ja', \n",
    "    logfilepath:str=logfilepath, con=conn):\n",
    "    \n",
    "    if not does_table_exist('pageviews'):\n",
    "        create_pageviews_table(con)\n",
    "    # start counts\n",
    "    process_start_time = dt.datetime.now()\n",
    "    file_count = 0\n",
    "    for year in years:\n",
    "        urls = get_pageviews_urls_by_year(year)\n",
    "        # urls = urls[:3] # truncate if debugging \n",
    "        for url in urls:\n",
    "            \n",
    "            # actual work\n",
    "            temp_fpath = download_file(url, dirpath='../data/temp/')\n",
    "            pageviews = get_pageviews_subset_by_proj_and_pagetitles(\n",
    "                            temp_fpath, pagetitles=pagetitles)\n",
    "            pageviews.to_sql(name='pageviews',con=con, if_exists='append', index=False)\n",
    "            \n",
    "            # complete counts\n",
    "            file_count += 1\n",
    "            # log and cleanup\n",
    "            log_forecast_of_completion(file_count, process_start_time, years)\n",
    "            os.remove(temp_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f552cfbe",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### does_table_exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf7fa03",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def does_table_exist(tablename:str, dbname:str='jawiki', con=conn) -> bool:\n",
    "    \"\"\"\n",
    "    run SQL query to look for tablename, return boolean\n",
    "    \"\"\"\n",
    "    sql = f\"\"\"\n",
    "    SELECT * \n",
    "        FROM information_schema.tables\n",
    "    WHERE table_schema = '{dbname}' \n",
    "        AND table_name = '{tablename}'\n",
    "    LIMIT 1;\n",
    "    \"\"\"\n",
    "    return bool(pd.read_sql(sql, con).shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b5254e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### create_pageviews_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8e2441",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_pageviews_table(con=conn):\n",
    "    \"\"\"\n",
    "    run SQL code to create pageviews table\n",
    "    \"\"\"\n",
    "    \n",
    "    sql = \"\"\"\n",
    "    CREATE TABLE pageviews (\n",
    "        row_id BIGINT(20) AUTO_INCREMENT PRIMARY KEY\n",
    "        ,page_id BIGINT(20)\n",
    "        ,utc_date DATE\n",
    "        ,utc_hourly_count TEXT\n",
    "    )\n",
    "    ;\n",
    "    \"\"\"\n",
    "    conn.execute(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b93556",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### tz_shift_hourly_views_utc2ja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c0e1da2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def tz_shift_hourly_views_utc2ja(ser:pd.Series) -> pd.Series:\n",
    "    AZ = string.ascii_uppercase\n",
    "    ja_tz_map = {i:j for i,j in zip(AZ[17:]+AZ[:17], AZ[:17]+AZ[17:])}\n",
    "    ja_tz_map = AZ.maketrans(ja_tz_map)\n",
    "    a = ser.str.extract('([R-Z].*$)').shift(1).fillna('')\n",
    "    b = ser.str.extract('((?:[A-Q][0-9]*)*)').fillna('')\n",
    "    c = (a+b).squeeze().str.translate(ja_tz_map)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f53f916",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "##### get_daily_views_from_hourly_views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b2f83523",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_daily_views_from_hourly_views(pd_obj):\n",
    "    if isinstance(pd_obj, pd.core.frame.DataFrame):\n",
    "        return pd_obj.applymap(lambda x: sum((int(i) for i in re.findall(r\"[A-Z]([0-9]*)\", x))))\n",
    "    if isinstance(pd_obj, pd.core.series.Series):\n",
    "        return pd_obj.map(lambda x: sum((int(i) for i in re.findall(r\"[A-Z]([0-9]*)\", x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cbae30",
   "metadata": {},
   "source": [
    "## main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac90f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_utc = get_pageviews_by_pageids_and_years([1051, 18508], [2016])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f728341",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ja = df.apply(tz_shift_hourly_views_utc2ja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "29d6d2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742fbaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ja.to_sql('test1', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5aebf25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquake_pids = [18508, 159816, 1051, 2339185, 1516544]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c61e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20e06f71",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e22fabd",
   "metadata": {},
   "source": [
    "run main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185aefe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "etl_pageviews_by_years_and_projects([2016,2017,2018,2019,2020,2021], all_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d2dc3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323c341e",
   "metadata": {},
   "source": [
    "### probably won't need this concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876f3b99",
   "metadata": {},
   "source": [
    "###### function tosql_utcdate_pageid_hourlycount_accessmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cfccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_pageviews_utc(paths:list[str]):\n",
    "    # bz2 fields: wiki_code, article_title, page_id, daily_total, hourly_counts\n",
    "    # sql fields: utc_date, page_id, hourly_count, access_method\n",
    "    \n",
    "    # check the line starts with \"ja.wikipedia\"\n",
    "    # split the line\n",
    "    # skip record if the list is too short\n",
    "    # skip record if there's no integer pageid\n",
    "    # convert access_method to integer:\n",
    "        # 'mobile': 1, 'desktop': 2, 'app': 3\n",
    "    # insert record to sql    \n",
    "    pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
