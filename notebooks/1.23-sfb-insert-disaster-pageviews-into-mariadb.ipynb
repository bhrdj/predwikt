{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48660241-8117-4a73-b0b4-df969997b4ec",
   "metadata": {},
   "source": [
    "# insert disaster pageviews into mariadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19abd44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mysql_user = 'ubuntu'\n",
    "# mysql_pass = input(f'Enter the MySQL password for user {mysql_user}: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "17eba2f0-f33b-40f6-ae44-30c348ca5a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, gzip, pickle, io, logging, inspect, functools\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd, datetime as dt\n",
    "import mysql.connector as mysql, sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18fa73d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "todays_date = dt.datetime.now(tz=dt.timezone(dt.timedelta(hours=8))).strftime('%Y-%m-%d')\n",
    "logfilepath = '../data/logs/pageviews-log_' + todays_date + '_' + str(0) + '.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e907f075",
   "metadata": {},
   "source": [
    "## setup logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcfab96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('1.22-sfb-get-pageviews-with-AWS')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# create file handler which logs even debug messages\n",
    "fh = logging.FileHandler(logfilepath)\n",
    "fh.setLevel(logging.DEBUG)\n",
    "# create console handler with a higher log level\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.ERROR)\n",
    "# create formatter and add it to the handlers\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fh.setFormatter(formatter)\n",
    "ch.setFormatter(formatter)\n",
    "# add the handlers to the logger\n",
    "logger.addHandler(fh)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "# USAGE: https://docs.python.org/3/howto/logging-cookbook.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83902168",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_args(func):\n",
    "    \"\"\"\n",
    "    Decorator to print function call details.\n",
    "    This includes parameters names and effective values.\n",
    "    \"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        func_args = inspect.signature(func).bind(*args, **kwargs).arguments\n",
    "        func_args_str = \", \".join(map(\"{0[0]} = {0[1]!r}\".format, func_args.items()))\n",
    "        logger.info(f\"start {func.__module__}.{func.__qualname__} ( {func_args_str} )\")\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        finally:\n",
    "            logger.info(f\"finish {func.__module__}.{func.__qualname__} ( {func_args_str} )\\n\")\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f3bab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_simply(func):\n",
    "    \"\"\"\n",
    "    Decorator to print function call details.\n",
    "    This includes parameters names and effective values.\n",
    "    \"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        func_args = inspect.signature(func).bind(*args, **kwargs).arguments\n",
    "        func_args_str = \", \".join(map(\"{0[0]} = {0[1]!r}\".format, func_args.items()))\n",
    "        logger.info(f\"start {func.__module__}.{func.__qualname__}\")\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        finally:\n",
    "            logger.info(f\"finish {func.__module__}.{func.__qualname__}\\n\")\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05b0f06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_errors(func):\n",
    "    \"\"\"\n",
    "    A decorator that wraps the passed in function and logs \n",
    "    exceptions should one occur\n",
    "    \"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except:\n",
    "            # log the exception\n",
    "            err = \"There was an exception in  \"\n",
    "            err += func.__name__\n",
    "            logger.exception(err)\n",
    "\n",
    "            # re-raise the exception\n",
    "            raise\n",
    "    return wrapper\n",
    "# https://www.blog.pythonlibrary.org/2016/06/09/python-how-to-create-an-exception-logging-decorator/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4293d3",
   "metadata": {},
   "source": [
    "##### login to mariadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bfb36a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_simply\n",
    "def connect_mariadb(host='localhost', user=mysql_user, passwd=mysql_pass, dbname='jawiki'):\n",
    "    \"\"\"\n",
    "    connect to mariadb and return: \n",
    "        cxn, cur, engine, conn\n",
    "    \"\"\"\n",
    "    cxn = mysql.connect(host=host,user=user,passwd=passwd, database=dbname)\n",
    "    cur = cxn.cursor()\n",
    "\n",
    "    connection_str = 'mysql+mysqlconnector://'+user+':'+passwd+'@'+host+'/'+dbname  # removed this after host +':'+dbport\n",
    "    try:\n",
    "        engine = sqlalchemy.create_engine(connection_str)\n",
    "        conn = engine.connect()\n",
    "    except Exception as e:\n",
    "        print('Database connection error - check creds')\n",
    "        print(e)\n",
    "    return cxn, cur, engine, conn\n",
    "\n",
    "cxn, cur, engine, conn = connect_mariadb()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2abe8c",
   "metadata": {},
   "source": [
    "## get page_titles and urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76935b99",
   "metadata": {},
   "source": [
    "###### unpickle list of pageids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31253407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def failed_decode(a):\n",
    "    try:\n",
    "        a.decode('utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def bytearray_to_str(a:bytearray, encoding='utf-8') -> str:\n",
    "    if type(a) != bytearray:\n",
    "        return a        \n",
    "    while failed_decode(a):\n",
    "        a = a[:-1]\n",
    "    return str(a.decode(encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da558220",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/processed/jawiki/' + 'disaster_descendants_raw.pickle', 'rb') as f:\n",
    "    disaster_descendants_raw = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2cfc7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_cat_page_ids = {'火山災害':2390743, '熱帯低気圧':626482, '雪害':2390774, '地震':135264, '津波':765772}  # '自然災害':137069, \n",
    "disasters_english = {'火山災害':'VolcanicDisaster', '熱帯低気圧':'TropicalCyclones', '雪害':'SnowDamage', '地震':'Earthquake', '津波':'Tsunami'}\n",
    "disasters = list(disaster_cat_page_ids.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4821135",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i in disaster_descendants_raw:\n",
    "    d[i] = (disaster_descendants_raw[i]\n",
    "            .drop_duplicates(subset='id')\n",
    "            .applymap(bytearray_to_str)\n",
    "           )\n",
    "    d[i] = d[i][d[i].namespace == 0]\n",
    "    d[i]['page_title'] = d[i].name.map(lambda x: str(x).split(sep='\\n')[-1])\n",
    "disaster_descendants = d\n",
    "del d, disaster_descendants_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "049f6e07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'type', 'namespace', 'page_title'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster_descendants['火山災害'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5acb587",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pageids = [j for i in disaster_descendants for j in disaster_descendants[i].id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee994dc",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b5a868",
   "metadata": {},
   "source": [
    "###### function get_pageview_series_by_pageids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a9339240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @log_simply\n",
    "def get_pageview_series_by_pageids(\n",
    "        datapath:str, pid_allowlist:list[int]\n",
    "        ) -> pd.Series:\n",
    "    \"\"\"\n",
    "    INPUTS: \n",
    "        datapath: path to pageviews_complete extract (single project only)\n",
    "        pid_shortlist: allowlist of pageids (sorted)\n",
    "    OUTPUTS: \n",
    "        pd.Series where:\n",
    "            index: page_id\n",
    "            value: encoded hourly counts (see note below)\n",
    "            name: date in yyyymmdd\n",
    "    NOTE:\n",
    "        hourly counts are encoded with letters as hours, and numbers as counts\n",
    "        for example, 'A2C1' means:\n",
    "            2 pageviews between 00:00 and 00:59\n",
    "            1 pageview between 02:00 and 02:59\n",
    "    \"\"\"\n",
    "    diz_views = {}\n",
    "    ct = 0\n",
    "    with open(datapath) as f:\n",
    "        while (line := f.readline()):\n",
    "            ct+=1\n",
    "            if ct%1000 == 0:\n",
    "                clear_output(wait=True)\n",
    "                print(ct)\n",
    "            line_split = line.split()\n",
    "            pid_str = line_split[2]\n",
    "            hour_counts = line_split[-1]\n",
    "            try: # ignore pageviews of redirects etc that don't have a page_id\n",
    "                pid = int(pid_str)\n",
    "            except ValueError:\n",
    "                continue \n",
    "            if pid in pid_allowlist:\n",
    "                diz_views[pid] = hour_counts\n",
    "    yyyymmdd = datapath.split('/')[-1].split('-')[1]\n",
    "    return pd.Series(diz_views, name=yyyymmdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ec3001d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = os.walk('../data/temp/jawiki_pageviews/')\n",
    "filepaths = []\n",
    "for tup in gen:\n",
    "    for f in tup[2]:\n",
    "        filepaths.append(tup[0]+'/'+f)\n",
    "filepaths.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1233cdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pageview_series_by_pageids(filepaths[0], all_pageids)\n",
    "\n",
    "# THIS IS TAKING TOO LONG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0fd99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "countlines(filepaths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a962d321",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = filepaths[0]\n",
    "pid_allowlist = all_pageids\n",
    "diz_views = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4259d476",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2aa662",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "902fa685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ja.wikipedia !!!Fuck_You!!! 625023 desktop 1 O1\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = f.readline()\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "925f8474",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_split = line.split()\n",
    "pid_str = line_split[2]\n",
    "hour_counts = line_split[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "064cedc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625023\n"
     ]
    }
   ],
   "source": [
    "try: # ignore pageviews of redirects etc that don't have a page_id\n",
    "    pid = int(pid_str)\n",
    "    print(pid)\n",
    "except ValueError as a:\n",
    "    print(f\"{type(a)} {a}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7204cb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not in pid_allowlist\n"
     ]
    }
   ],
   "source": [
    "if pid in pid_allowlist:\n",
    "    diz_views[pid] = hour_counts\n",
    "    print(f\"{pid}: {hour_counts}\")\n",
    "else:\n",
    "    print(\"not in pid_allowlist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8872bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3078665e",
   "metadata": {},
   "outputs": [],
   "source": [
    "yyyymmdd = datapath.split('/')[-1].split('-')[1]\n",
    "diz_views = pd.Series(diz_views, name=yyyymmdd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bbc3b2",
   "metadata": {},
   "source": [
    "###### functions to put pageviews into SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfa77329",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_args\n",
    "def does_table_exist(tablename:str, dbname:str='jawiki', con=conn) -> bool:\n",
    "    \"\"\"\n",
    "    run SQL query to look for tablename, return boolean\n",
    "    \"\"\"\n",
    "    sql = f\"\"\"\n",
    "    SELECT * \n",
    "        FROM information_schema.tables\n",
    "    WHERE table_schema = '{dbname}' \n",
    "        AND table_name = '{tablename}'\n",
    "    LIMIT 1;\n",
    "    \"\"\"\n",
    "    return bool(pd.read_sql(sql, con).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e78b562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_args\n",
    "def create_pageviews_table(con=conn):\n",
    "    \"\"\"\n",
    "    run SQL code to create pageviews table\n",
    "    \"\"\"\n",
    "    \n",
    "    sql = \"\"\"\n",
    "    CREATE TABLE pageviews (\n",
    "        row_id BIGINT(20) AUTO_INCREMENT PRIMARY KEY\n",
    "        ,page_id BIGINT(20)\n",
    "        ,utc_date DATE\n",
    "        ,utc_hourly_count TEXT\n",
    "    )\n",
    "    ;\n",
    "    \"\"\"\n",
    "    conn.execute(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cbae30",
   "metadata": {},
   "source": [
    "## main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5fbe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_errors\n",
    "def etl_pageviews_by_years_and_projects(years:list[int], \n",
    "                                        pagetitles:list[str],\n",
    "                                        project:str='ja', \n",
    "                                        logfilepath:str=logfilepath, \n",
    "                                        con=conn):\n",
    "    if not does_table_exist('pageviews'):\n",
    "        create_pageviews_table(con)\n",
    "    # start counts\n",
    "    process_start_time = dt.datetime.now()\n",
    "    file_count = 0\n",
    "    for year in years:\n",
    "        urls = get_pageviews_urls_by_year(year)\n",
    "        # urls = urls[:3] # truncate if debugging \n",
    "        for url in urls:\n",
    "            \n",
    "            # actual work\n",
    "            temp_fpath = download_file(url, dirpath='../data/temp/')\n",
    "            pageviews = get_pageviews_subset_by_proj_and_pagetitles(\n",
    "                            temp_fpath, pagetitles=pagetitles)\n",
    "            pageviews.to_sql(name='pageviews',con=con, if_exists='append', index=False)\n",
    "            \n",
    "            # complete counts\n",
    "            file_count += 1\n",
    "            # log and cleanup\n",
    "            log_forecast_of_completion(file_count, process_start_time, years)\n",
    "            os.remove(temp_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e06f71",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e22fabd",
   "metadata": {},
   "source": [
    "run main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185aefe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "etl_pageviews_by_years_and_projects([2016,2017,2018,2019,2020,2021], all_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d2dc3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da92497b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql('select count(*) from pageviews;', con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3fe36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql('desc pageviews;', con=conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268ac7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_sql('show tables;', con=conn)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d98b0b1",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "pd.read_sql('select * from pageviews order by datetime_viewed_UTC desc limit 5;', con=conn, index_col='row_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f68421",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29ee029",
   "metadata": {},
   "source": [
    "## get it working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32694b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '../data/temp/jawiki_pageviews/2016/2016-01/pageviews-20160102-user'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfcd584",
   "metadata": {},
   "outputs": [],
   "source": [
    "volc_ids = disaster_descendants['火山災害'].id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4518f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getline(n):    \n",
    "    with open(datapath) as f:\n",
    "        for i in range(n-1):\n",
    "            line = f.readline()\n",
    "        print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "432e2ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def countlines(path):\n",
    "    ct = 0\n",
    "    with open(path) as f:\n",
    "        while True:\n",
    "            try:\n",
    "                line = f.readline()\n",
    "            except:\n",
    "                break\n",
    "    return ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b923d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "getline(400243)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4060c050",
   "metadata": {},
   "outputs": [],
   "source": [
    "title, line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476253d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_pids, ct_diz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e33c4b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b81d79",
   "metadata": {},
   "source": [
    "#### how to do jupyter with aws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09261b01",
   "metadata": {},
   "source": [
    "- https://dataschool.com/data-modeling-101/running-jupyter-notebook-on-an-ec2-server/\n",
    "    - except jupyter_notebook_config.py_ should be ...config.py instead\n",
    "- https://gist.github.com/J535D165/0e840291e7b2598ec157e13e9b9ca569\n",
    "    - trying this for how to use nohup\n",
    "- some medium [article](https://medium.com/@christinakouride/a-beginners-guide-to-running-jupyter-notebook-on-amazon-ec2-69e1b74e73cc#:~:text=Your%20Jupyter%20Notebook%20server%20will,for%20time%20not%20using%20it.)\n",
    "    - they pointed out that notebook will keep running, but didn't mention nohup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861e6745",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d091082",
   "metadata": {},
   "source": [
    "#### run this in root console\n",
    "```sql\n",
    "set global net_buffer_length=1000000; \n",
    "set global max_allowed_packet=1000000000;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344c3d50",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "id": "75550829",
   "metadata": {},
   "source": [
    "# nohup jupyter notebook &"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4212a64",
   "metadata": {},
   "source": [
    "# !jupyter nbconvert --to script '1.22-sfb-get-pageviews-with-AWS-lambda.ipynb'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d2de286",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1639844a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bc2462",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f348120",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858e7da3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec38d37",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43377fb5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4414d09",
   "metadata": {},
   "source": [
    "#### run this in root console\n",
    "```sql\n",
    "set global net_buffer_length=1000000; \n",
    "set global max_allowed_packet=1000000000;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd55e4f6",
   "metadata": {},
   "source": [
    "###### function ```subset_pageviews_by_page_titles``` to clean and filter pageview records"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e592660a",
   "metadata": {},
   "source": [
    "def subset_pageviews_by_page_titles(fpath_in, fpath_out, page_titles, proj='ja'):\n",
    "    os.makedirs(os.path.dirname(fpath_out), exist_ok=True)\n",
    "    with (open_hour_file(fpath_in) as f_in, \n",
    "          open(fpath_out, 'w', encoding='utf-8') as f_out\n",
    "         ):\n",
    "        while (line := f_in.readline()):\n",
    "            if line[:3] != proj + ' ':\n",
    "                continue\n",
    "            lst = line.strip().split(sep=' ')\n",
    "            if lst[1] in page_titles:\n",
    "                f_out.write(line)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "57484a87",
   "metadata": {},
   "source": [
    "###### function ```subset_pageviews_by_project``` to clean and filter pageview records"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7e560dad",
   "metadata": {},
   "source": [
    "def subset_pageviews_by_project(fpath_in, fpath_out, proj='ja'):\n",
    "    os.makedirs(os.path.dirname(fpath_out), exist_ok=True)\n",
    "    with (open_hour_file(fpath_in) as f_in, \n",
    "          open(fpath_out, 'w', encoding='utf-8') as f_out\n",
    "         ):\n",
    "        while (line := f_in.readline()):\n",
    "            if line[:3] != proj + ' ':\n",
    "                continue\n",
    "            f_out.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7202ba2d",
   "metadata": {},
   "source": [
    "###### FOUND OUT THAT THERE'RE SOME UNRELATED COLUMNS IN THE CATEGORIES:\n",
    "NEED TO CLEAN THE CATEGORIES"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bb5fb98b",
   "metadata": {},
   "source": [
    "for i in disaster_descendants:\n",
    "    print(i)\n",
    "    print(disaster_descendants[i][disaster_descendants[i].page_title.isin(['WHITEBERRY'])])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ebf2072",
   "metadata": {},
   "source": [
    "disaster_descendants['火山災害'][disaster_descendants['火山災害'].page_title.isin(['WHITEBERRY'])]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ac73caff",
   "metadata": {},
   "source": [
    "all_titles[5444:5470]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ea46b76",
   "metadata": {},
   "source": [
    "[i for i in all_titles if i == 'WHITEBERRY']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
