{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48660241-8117-4a73-b0b4-df969997b4ec",
   "metadata": {},
   "source": [
    "# insert disaster pageviews into mariadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d99b2b5",
   "metadata": {},
   "source": [
    "##### password, imports, mariadb_login"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3755d68",
   "metadata": {},
   "source": [
    "###### password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "19abd44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mysql_user = 'ubuntu'\n",
    "# mysql_pass = input(f'Enter the MySQL password for user {mysql_user}: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcd000e",
   "metadata": {},
   "source": [
    "###### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "17eba2f0-f33b-40f6-ae44-30c348ca5a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, gzip, pickle, io, logging, inspect, functools\n",
    "from IPython.display import clear_output\n",
    "import pandas as pd, datetime as dt\n",
    "import mysql.connector as mysql, sqlalchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4293d3",
   "metadata": {},
   "source": [
    "###### login to mariadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0bfb36a0",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def connect_mariadb(host='localhost', user=mysql_user, passwd=mysql_pass, dbname='jawiki'):\n",
    "    \"\"\"\n",
    "    connect to mariadb and return: \n",
    "        cxn, cur, engine, conn\n",
    "    \"\"\"\n",
    "    cxn = mysql.connect(host=host,user=user,passwd=passwd, database=dbname)\n",
    "    cur = cxn.cursor()\n",
    "\n",
    "    connection_str = 'mysql+mysqlconnector://'+user+':'+passwd+'@'+host+'/'+dbname  # removed this after host +':'+dbport\n",
    "    try:\n",
    "        engine = sqlalchemy.create_engine(connection_str)\n",
    "        conn = engine.connect()\n",
    "    except Exception as e:\n",
    "        print('Database connection error - check creds')\n",
    "        print(e)\n",
    "    return cxn, cur, engine, conn\n",
    "\n",
    "cxn, cur, engine, conn = connect_mariadb()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2abe8c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## get page_titles and urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76935b99",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### unpickle list of disaster pageids (diz_pageids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31253407",
   "metadata": {
    "code_folding": [
     0,
     7
    ],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def failed_decode(a):\n",
    "    try:\n",
    "        a.decode('utf-8')\n",
    "    except UnicodeDecodeError:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def bytearray_to_str(a:bytearray, encoding='utf-8') -> str:\n",
    "    if type(a) != bytearray:\n",
    "        return a        \n",
    "    while failed_decode(a):\n",
    "        a = a[:-1]\n",
    "    return str(a.decode(encoding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da558220",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('../data/processed/jawiki/' + 'disaster_descendants_raw.pickle', 'rb') as f:\n",
    "    disaster_descendants_raw = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2cfc7fc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "disaster_cat_page_ids = {'火山災害':2390743, '熱帯低気圧':626482, '雪害':2390774, '地震':135264, '津波':765772}  # '自然災害':137069, \n",
    "disasters_english = {'火山災害':'VolcanicDisaster', '熱帯低気圧':'TropicalCyclones', '雪害':'SnowDamage', '地震':'Earthquake', '津波':'Tsunami'}\n",
    "disasters = list(disaster_cat_page_ids.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4821135",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i in disaster_descendants_raw:\n",
    "    d[i] = (disaster_descendants_raw[i]\n",
    "            .drop_duplicates(subset='id')\n",
    "            .applymap(bytearray_to_str)\n",
    "           )\n",
    "    d[i] = d[i][d[i].namespace == 0]\n",
    "    d[i]['page_title'] = d[i].name.map(lambda x: str(x).split(sep='\\n')[-1])\n",
    "disaster_descendants = d\n",
    "del d, disaster_descendants_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "049f6e07",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'name', 'type', 'namespace', 'page_title'], dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disaster_descendants['火山災害'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f5acb587",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "diz_pageids = [j for i in disaster_descendants for j in disaster_descendants[i].id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14571f0b",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "###### make dict pageid_sorter:  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f5994d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "keys: all pageids in jawiki  \n",
    "values: disaster 1, not-disaster 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0abafb8",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def make_pageid_sorter(pid_allowlist:list[int], con=conn) -> dict:\n",
    "    ct = 0\n",
    "    sql = \"select distinct page_id from page;\"\n",
    "    all_pageids = pd.read_sql(sql, conn).squeeze().to_list()\n",
    "    d = {i:0 for i in all_pageids}\n",
    "    for i in pid_allowlist:\n",
    "        d[i] = 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ead6f5cd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "pageid_sorter = make_pageid_sorter(diz_pageids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9922dbf2",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pageid_sorter_path = '../data/processed/jawiki/pageid_sorter.pickle'"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c76c0d21",
   "metadata": {
    "hidden": true
   },
   "source": [
    "with open(pageid_sorter_path, 'wb+') as f:\n",
    "    pickle.dump(pageid_sorter, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e3d23fb7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(pageid_sorter_path, 'rb') as f:\n",
    "    pageid_sorter = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ce981beb",
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3896661"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_pageids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee994dc",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecd0ea0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### function get_all_paths_in_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "29fbf5bb",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def get_all_paths_in_year(year:int) -> list[str]:\n",
    "    gen = os.walk(f'../data/temp/jawiki_pageviews/{year}/')\n",
    "    filepaths = []\n",
    "    for tup in gen:\n",
    "        for f in tup[2]:\n",
    "            filepaths.append(tup[0]+'/'+f)\n",
    "    filepaths.sort()\n",
    "    return filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b5a868",
   "metadata": {},
   "source": [
    "###### function get_pageview_series_by_pageids_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "94a01fc6",
   "metadata": {
    "code_folding": [
     5,
     8,
     14
    ]
   },
   "outputs": [],
   "source": [
    "# HAVEN'T IMPLEMENTED THE DATAFRAME WITH DIFFERENT ACCESS_METHOD FIELDS YET - HALFWAY DONE\n",
    "def get_pageviews_by_pageid_years(\n",
    "        pids_of_interest:list[int], years:[int]\n",
    "        ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    INPUTS: \n",
    "        pid_of_interest: pageid to return\n",
    "        years: list of years to include\n",
    "    OUTPUTS: \n",
    "        pd.DataFrame where:\n",
    "            index: utc_date in yyyymmdd\n",
    "            columns: 'mobile', 'desktop', 'app'\n",
    "            values: encoded hourly counts (see note below)\n",
    "            name: pageid\n",
    "    NOTE:\n",
    "        hourly counts are encoded with letters as hours, and numbers as counts\n",
    "        for example, 'C2' means 2 pageviews between 02:00 and 02:59\n",
    "    \"\"\"\n",
    "    paths = []\n",
    "    for year in years:\n",
    "        paths = paths + get_all_paths_in_year(year)\n",
    "    pageid_sorter = make_pageid_sorter(pids_of_interest)\n",
    "    diz_views = {}\n",
    "    for path in paths[:20]:\n",
    "        yyyymmdd = path.split('/')[-1].split('-')[1]\n",
    "        with open(path) as f:\n",
    "            try: \n",
    "                diz_views[yyyymmdd]\n",
    "            except KeyError:\n",
    "                diz_views[yyyymmdd] = {}\n",
    "            while (line := f.readline()):\n",
    "                line_split = line.split()\n",
    "                if len(line_split) < 6:\n",
    "                    continue\n",
    "                pid_str = line_split[2]\n",
    "                try: # ignore pageviews of redirects etc that don't have a page_id\n",
    "                    pid = int(pid_str)\n",
    "                except ValueError:\n",
    "                    continue \n",
    "                try:\n",
    "                    (ps:=pageid_sorter[pid])\n",
    "                except KeyError:\n",
    "                    continue\n",
    "                if ps==1:\n",
    "                    access_method = line_split[3]\n",
    "                    hour_counts = line_split[5]\n",
    "                    diz_views[yyyymmdd][pid_str+'_'+access_method] = hour_counts\n",
    "        clear_output(wait=True)\n",
    "        print(f\"started {min(years)},\\ncompleted {yyyymmdd},\\ncontinuing until end of {max(years)}\")\n",
    "    return pd.DataFrame(diz_views).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e54d5b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquake_pids = [18508, 159816, 1051, 2339185, 1516544]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "2c14f1c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18508, 159816, 1051, 2339185, 1516544]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earthquake_pids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "958c5836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started 2016,\n",
      "completed 20160120,\n",
      "continuing until end of 2016\n"
     ]
    }
   ],
   "source": [
    "earthquake_pageviews = get_pageviews_by_pageid_years([1051], [2016])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "a53a727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = earthquake_pageviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "774502f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "AZ = string.ascii_uppercase\n",
    "ja_tz_map = {i:j for i,j in zip(AZ[17:]+AZ[:17], AZ[:17]+AZ[17:])}\n",
    "ja_tz_map = AZ.maketrans(ja_tz_map)\n",
    "del AZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "b53c6e5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20160101    J3K4L4M2N5O5P8Q5R8S7T4U4V2W4X6Y4Z2\n",
       "20160102                      A3B1E2F1G2K1T1W1\n",
       "20160103                              A1N1W1X1\n",
       "20160104                                  J1L1\n",
       "20160105                                    O2\n",
       "20160106                            L1N1Q1V1X1\n",
       "20160107                              F1M1U1X1\n",
       "20160108                              J1O1P1Z2\n",
       "20160109                              M1O3U6Y1\n",
       "20160110                                    R1\n",
       "20160111                                    P1\n",
       "20160112                          J1K1L3N2U1V1\n",
       "20160113                            J4K4N2P1Q1\n",
       "20160114                                L1M1P3\n",
       "20160115                                  K2O1\n",
       "20160116                                  K1P1\n",
       "20160117                              F1L1M2Q1\n",
       "20160118                                  P1S1\n",
       "20160119                                    B1\n",
       "20160120                              B1L1P1R1\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df['1051_desktop'].str.extract('([R-Z].*$)').shift(1).fillna('')\n",
    "b = df['1051_desktop'].str.extract('((?:[A-Q][0-9]*)*)').fillna('')\n",
    "c = (a+b).squeeze().str.translate(ja_tz_map)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c2b217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "92e40254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ja.wikipedia ! 124376 desktop 2 L1S1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(datapath) as f:\n",
    "    print(f.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46d6bec",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "###### functions to put pageviews into SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfa77329",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def does_table_exist(tablename:str, dbname:str='jawiki', con=conn) -> bool:\n",
    "    \"\"\"\n",
    "    run SQL query to look for tablename, return boolean\n",
    "    \"\"\"\n",
    "    sql = f\"\"\"\n",
    "    SELECT * \n",
    "        FROM information_schema.tables\n",
    "    WHERE table_schema = '{dbname}' \n",
    "        AND table_name = '{tablename}'\n",
    "    LIMIT 1;\n",
    "    \"\"\"\n",
    "    return bool(pd.read_sql(sql, con).shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e78b562d",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_pageviews_table(con=conn):\n",
    "    \"\"\"\n",
    "    run SQL code to create pageviews table\n",
    "    \"\"\"\n",
    "    \n",
    "    sql = \"\"\"\n",
    "    CREATE TABLE pageviews (\n",
    "        row_id BIGINT(20) AUTO_INCREMENT PRIMARY KEY\n",
    "        ,page_id BIGINT(20)\n",
    "        ,utc_date DATE\n",
    "        ,utc_hourly_count TEXT\n",
    "    )\n",
    "    ;\n",
    "    \"\"\"\n",
    "    conn.execute(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cbae30",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5fbe64",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def etl_pageviews_by_years_and_projects(years:list[int], \n",
    "                                        pagetitles:list[str],\n",
    "                                        project:str='ja', \n",
    "                                        logfilepath:str=logfilepath, \n",
    "                                        con=conn):\n",
    "    if not does_table_exist('pageviews'):\n",
    "        create_pageviews_table(con)\n",
    "    # start counts\n",
    "    process_start_time = dt.datetime.now()\n",
    "    file_count = 0\n",
    "    for year in years:\n",
    "        urls = get_pageviews_urls_by_year(year)\n",
    "        # urls = urls[:3] # truncate if debugging \n",
    "        for url in urls:\n",
    "            \n",
    "            # actual work\n",
    "            temp_fpath = download_file(url, dirpath='../data/temp/')\n",
    "            pageviews = get_pageviews_subset_by_proj_and_pagetitles(\n",
    "                            temp_fpath, pagetitles=pagetitles)\n",
    "            pageviews.to_sql(name='pageviews',con=con, if_exists='append', index=False)\n",
    "            \n",
    "            # complete counts\n",
    "            file_count += 1\n",
    "            # log and cleanup\n",
    "            log_forecast_of_completion(file_count, process_start_time, years)\n",
    "            os.remove(temp_fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e06f71",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e22fabd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "run main program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185aefe4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "etl_pageviews_by_years_and_projects([2016,2017,2018,2019,2020,2021], all_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d2dc3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323c341e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### probably won't need this concept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876f3b99",
   "metadata": {
    "hidden": true
   },
   "source": [
    "###### function tosql_utcdate_pageid_hourlycount_accessmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "97cfccd7",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def populate_pageviews_utc(paths:list[str]):\n",
    "    # bz2 fields: wiki_code, article_title, page_id, daily_total, hourly_counts\n",
    "    # sql fields: utc_date, page_id, hourly_count, access_method\n",
    "    \n",
    "    # check the line starts with \"ja.wikipedia\"\n",
    "    # split the line\n",
    "    # skip record if the list is too short\n",
    "    # skip record if there's no integer pageid\n",
    "    # convert access_method to integer:\n",
    "        # 'mobile': 1, 'desktop': 2, 'app': 3\n",
    "    # insert record to sql    \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5643256e",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## get it working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aff4b6e",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "datapath = '../data/temp/jawiki_pageviews/2016/2016-01/pageviews-20160102-user'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1647f1",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "volc_ids = disaster_descendants['火山災害'].id.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cf315a",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def getline(n):    \n",
    "    with open(datapath) as f:\n",
    "        for i in range(n-1):\n",
    "            line = f.readline()\n",
    "        print(f.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4c97f080",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def countlines(path):\n",
    "    ct = 0\n",
    "    with open(path) as f:\n",
    "        while True:\n",
    "            try:\n",
    "                line = f.readline()\n",
    "            except:\n",
    "                break\n",
    "    return ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f7b268",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "getline(400243)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a309ec26",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "title, line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d47bb4",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ct_pids, ct_diz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c132435d",
   "metadata": {
    "hidden": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8849f8ba",
   "metadata": {
    "hidden": true
   },
   "source": [
    "# @log_simply\n",
    "def get_pageview_series_by_pageids(\n",
    "        datapath:str, pid_allowlist:list[int]\n",
    "        ) -> pd.Series:\n",
    "    \"\"\"\n",
    "    INPUTS: \n",
    "        datapath: path to pageviews_complete extract (single project only)\n",
    "        pid_shortlist: allowlist of pageids (sorted)\n",
    "    OUTPUTS: \n",
    "        pd.Series where:\n",
    "            index: page_id\n",
    "            value: encoded hourly counts (see note below)\n",
    "            name: date in yyyymmdd\n",
    "    NOTE:\n",
    "        hourly counts are encoded with letters as hours, and numbers as counts\n",
    "        for example, 'A2C1' means:\n",
    "            2 pageviews between 00:00 and 00:59\n",
    "            1 pageview between 02:00 and 02:59\n",
    "    \"\"\"\n",
    "    diz_views = {}\n",
    "    ct = 0\n",
    "    with open(datapath) as f:\n",
    "        while (line := f.readline()):\n",
    "            ct+=1\n",
    "            line_split = line.split()\n",
    "            pid_str = line_split[2]\n",
    "            hour_counts = line_split[-1]\n",
    "            if ct%10000 == 0:\n",
    "                clear_output(wait=True)\n",
    "                print(f\"{ct}, {pid_str}\")\n",
    "            try: # ignore pageviews of redirects etc that don't have a page_id\n",
    "                pid = int(pid_str)\n",
    "            except ValueError:\n",
    "                continue \n",
    "            if pid in pid_allowlist:\n",
    "                diz_views[pid] = hour_counts\n",
    "    yyyymmdd = datapath.split('/')[-1].split('-')[1]\n",
    "    return pd.Series(diz_views, name=yyyymmdd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
